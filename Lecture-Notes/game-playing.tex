\chapter{Playing Games}
One major breakthrough for the field of artificial intelligence happened in 1997 when the chess-playing computer
\href{https://en.wikipedia.org/wiki/Deep_Blue_(chess_computer)}{Deep Blue} was able to beat the World Chess
Champion \href{https://en.wikipedia.org/wiki/Garry_Kasparov}{Garry Kasparov} by $3\sfrac{1}{2}-2\sfrac{1}{2}$.
While \blue{Deep Blue} was based on special hardware, according to the
\href{http://www.computerchess.org.uk/ccrl/4040/rating_list_all.html}{computer chess rating list} of the 24th
of March 2018, the chess program \href{https://en.wikipedia.org/wiki/Stockfish_(chess)}{Stockfish} runs
on ordinary desktop computers and has an \href{https://en.wikipedia.org/wiki/Elo_rating_system}{Elo rating} of 3445.  
To compare, according to the
\href{https://ratings.fide.com/top.phtml?list=men}{Fide} list of March 2018, the current 
World Chess Champion \href{https://en.wikipedia.org/wiki/Magnus_Carlsen}{Magnus Carlsen} has an Elo rating of
just 2843.  Hence, he wouldn't stand a chance to win a game against Stockfish.  More recently, the computer program
\href{https://en.wikipedia.org/wiki/AlphaGo}{AlphaGo} was able to beat
\href{https://en.wikipedia.org/wiki/Ke_Jie}{Ke Jie}, who is currently\footnote{This assessment is of March 2018.} 
considered to be the best human \href{https://en.wikipedia.org/wiki/Go_(game)}{go} player in the world.
Besides go and chess, there are many other games where today the performance of a computer exceeds the
performance of human players.  To name just one more example, at the beginning of 2017 the program
\href{https://en.wikipedia.org/wiki/Libratus}{Libratus} was able to  
\href{https://www.engadget.com/2017/01/31/libratus-the-poker-playing-ai-destroyed-its-four-human-rivals/}{beat}
four professional poker players resoundingly.

In this chapter we want to investigate how a computer can play a game.  To this end we define a
\blue{game} $\mathcal{G}$ as a six-tuple
\\[0.2cm]
\hspace*{1.3cm}
$\mathcal{G} = \langle \texttt{States}, s_0, \texttt{Players}, \texttt{nextStates}, \texttt{finished},\texttt{utility} \rangle$
\\[0.2cm]
where the components are interpreted as follows:
\begin{enumerate}
\item $\texttt{States}$ is the set of all possible \blue{states} of the game.
\item $s_0 \in \texttt{startState}$ is the \blue{start state}.
\item $\texttt{Players}$ is  the list of \blue{players} of the game.  The first element in \texttt{Players} is
      the player to start the game and after that the players take turns.
\item $\texttt{nextStates}$ is a function that takes a state $s \in \texttt{States}$ and a player $p \in \texttt{Players}$ and returns the set of
      states that can be reached if the player $p$ has to make a move in the state $s$.  Hence, the signature of
      $\texttt{nextStates}$ is given as follows:
      \\[0.2cm]
      \hspace*{1.3cm}
      $\texttt{nextStates}: \texttt{States} \times \texttt{Players} \rightarrow 2^{\texttt{States}}$.
\item $\texttt{finished}$ is a function that takes a state $s$ and decides whether the games is finished.
      Therefore, the signature of $\texttt{finished}$ is
      \\[0.2cm]
      \hspace*{1.3cm}
      $\texttt{finished}: \texttt{States} \rightarrow \mathbb{B}$.
      \\[0.2cm]
      Here, $\mathbb{B}$ is the set of Boolean values, i.e.~we have $\mathbb{B} := \{ \texttt{true}, \texttt{false} \}$.
  
      Using the function $\texttt{finished}$, we define the set $\texttt{TerminalStates}$ as the set of those
      states such that the game has finished,  i.e.~we define
      \\[0.2cm]
      \hspace*{1.3cm}
      $\texttt{TerminalStates} := \{ s \in \texttt{States} \mid \texttt{finished}(s) \}$.
\item $\texttt{utility}$ is a function that takes a state $s \in \texttt{TerminalStates}$ and a player $p \in \texttt{Players}$.  If returns
      the \blue{value} that the game has for player $p$.  In all of our examples, this value will be an element
      from the set $\{-1, 0, +1\}$.  The value $-1$ indicates that player $p$ has lost the game,
      if the value is $+1$ the player $p$ has won the game and if this value is $0$, then the game is drawn.
      Hence the signature of $\texttt{utility}$ is
      \\[0.2cm]
      \hspace*{1.3cm}
      $\texttt{utility}: \texttt{TerminalStates} \times \texttt{Players} \rightarrow \{ -1, 0, +1\}$.
\end{enumerate}

\exercise
The definition given above does not capture all types of games.  In particular, the definition only captures 
\blue{deterministic games}:  A game is called \blue{deterministic} iff there is no randomness
involved.  Games like chess and go are certainly deterministic.  However, other games like 
\href{https://en.wikipedia.org/wiki/Dice_chess}{dice chess} involve randomness.  In dice chess a pair of dice is
rolled at the beginning of each turn.  The outcome of this roll determines which pieces may be moved.
Extend the definition of a
game so that also a games like \blue{dice chess} can be described. 
\eox

In this chapter we will only consider so called \blue{two person zero sum games}.  This means that the list $\texttt{Players}$
has exactly two elements.  If we call these players $\mathrm{A}$ and $\mathrm{B}$, i.e.~if we have
\\[0.2cm]
\hspace*{1.3cm}
$\texttt{Players} = \bigl[ \mathrm{A}, \mathrm{B} \bigr]$,
\\[0.2cm]
then the game is called a \blue{zero sum game} iff we have
\\[0.2cm]
\hspace*{1.3cm}
$\forall s \in \texttt{TerminalStates}:\texttt{utility}(s, \texttt{A}) + \texttt{utility}(s, \texttt{B}) = 0$,
\\[0.2cm]
i.e.~the losses of player $\mathrm{A}$ are compensated by the wins of player $\texttt{B}$ and vice versa.
Games like \href{https://en.wikipedia.org/wiki/Go_(game)}{go} and 
\href{https://en.wikipedia.org/wiki/Chess}{chess} are two person zero sum games.
We proceed to discuss an example of a game.

\section{Tic-Tac-Toe}
The game \href{https://en.wikipedia.org/wiki/Tic-tac-toe}{tic-tac-toe} is played on a square board of size 
$3 \times 3$.  On every turn, one player puts an ``\texttt{X}'' on one of the free squares of the board, while
the other player puts an ``$\texttt{O}$'' onto a free square when it is his turn.  If the first player manages
to place three \texttt{X}s in a 
row, column, or diagonal, she has won the game.  Similarly, if the other player manages to put three \texttt{O}s in a
row, column, or diagonal, this player is the winner.  Otherwise, the game is drawn.
\myFig{ttt.stlx} shows a \textsc{SetlX} implementation of tic-tac-toe.


\begin{figure}[!ht]
\centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  firstnumber   = 1,
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.0cm,
                  xrightmargin  = 0.0cm,
                  ]
    players    := [] |-> [ "X", "O" ];
    startState := [] |-> [ [ " " : col in [1..3]] : row in [1..3] ];
    nextStates := procedure(State, player) {
        Empty  := empty(State);
        Result := {};
        for ([row, col] in Empty) {
            NextState           := State;
            NextState[row][col] := player;
            Result              += { NextState };
        }
        return Result;
    };
    empty := S |-> {[row,col] : row in [1..3], col in [1..3] | S[row][col]==" "};
    utility := procedure(State, player) {
        Lines := all_lines(State);
        for (Line in Lines) {
            if (#Line == 1 && Line != { " " }) {
                if (Line == { player }) { return  1; } else { return -1; }
            }
        }
        if (forall(row in [1..3], col in [1..3] | State[row][col] != " ")) {
            return 0;   
        }
    };
    all_lines := procedure(State) {
        Lines := { { State[row][ col] : col in [1..3] } : row in [1..3] };
        Lines += { { State[row][ col] : row in [1..3] } : col in [1..3] };
        Lines += { { State[idx][ idx] : idx in [1..3] } };
        Lines += { { State[idx][-idx] : idx in [1..3] } };
        return Lines;
    };
    finished := procedure(State) {
        return utility(State, "X") != om;
    };
\end{Verbatim}
\vspace*{-0.3cm}
\caption{A \textsc{SetlX} description of tic-tac-toe.}
\label{fig:ttt.stlx}
\end{figure}
 

\begin{enumerate}
\item The function $\texttt{players}$ returns the set $\texttt{Players}$.  Traditionally, the players in
      tic-tac-toe are called \texttt{X} and \texttt{O}.
\item The function $\texttt{startState}$ returns the start state, which is an empty board.
      States are represented as list of lists.  The entries in these lists are the characters 
      ``\texttt{X}'', ``\texttt{O}'', and ``\texttt{ }''.
      As the  $\texttt{StartState}$ is the empty board, it is represented as as follows:
      \begin{Verbatim}
      [ [" ", " ", " "], 
        [" ", " ", " "], 
        [" ", " ", " "]
      ].     
      \end{Verbatim}
\item The function $\texttt{nextStates}$ takes a $\texttt{State}$ and a $\texttt{player}$ and computes the set
      of states that can be reached from $\texttt{State}$ if $\texttt{player}$ is to move next.
      To this end, it first computes the set of \blue{empty} positions.  Every position is represented as pair of the
      form $[\texttt{row}, \texttt{col}]$ where $\texttt{row}$ specifies the row and $\texttt{col}$ specifies
      the column of the position.  A position is \blue{empty} iff
      \\[0.2cm]
      \hspace*{1.3cm}
      $[\texttt{row}, \texttt{col}] = \texttt{\symbol{34}\;\;\symbol{34}}$.
      \\[0.2cm]
      The computation of the empty position has been sourced out to the function $\texttt{empty}$.
      The function $\texttt{nextStates}$ then iterates over the set of empty positions. For every 
      empty position $[\texttt{row}, \texttt{col}]$ it creates a new state $\texttt{NextState}$ that results
      from the current $\texttt{State}$ by putting the mark of $\texttt{player}$ in this position.  
      The resulting states are collected in the set $\texttt{Result}$ and returned.
\item The function $\texttt{empty}$ takes a state $\texttt{S}$ and returns the set of positions that are empty
      in this state.
\item The function $\texttt{utility}$ takes a $\texttt{State}$ and a $\texttt{player}$.  If the game is 
      finished in the given $\texttt{State}$, it returns the value that this $\texttt{State}$ has for the
      current $\texttt{player}$.  If the game is not yet decided, $\Omega$ is returned instead.
 
      In order to achieve its goal, the procedure first computes the set of all \blue{line-sets}.
      Given a $\texttt{State}$, a \blue{line-set} is a set of those markers that either form a horizontal,
      vertical, or diagonal line in $\texttt{State}$, e.g.~the set 
      \\[0.2cm]
      \hspace*{1.3cm}
      $\{\, \texttt{State}[1,1],\, \texttt{State}[2,2],\, \texttt{State}[3,3]\, \}$
      \\[0.2cm]
      is the set of entries in a diagonal line.  The game is decided if all entries in this set are either
      ``$\texttt{X}$'' or ``$\texttt{O}$''.  In this case, the set has exactly one element which is different
      from the blank.  If this element is the same as $\texttt{player}$, then the game is won by
      $\texttt{player}$, otherwise it is lost.

      Finally, if there are no empty squares left, then the game is a draw.
\item The auxiliary procedure $\texttt{all\_lines}$ takes a $\texttt{State}$ and computes the set $\texttt{Lines}$ of all
      \blue{line-sets}. 
      \begin{enumerate}
      \item For any $\mathrm{row} \in \{1,2,3\}$ the set 
            \\[0.2cm]
            \hspace*{1.3cm}
            \texttt{\{ State[row][col] : col in [1..3]\}} 
            \\[0.2cm]
            forms a horizontal line. 
      \item Likewise, for any $\mathrm{col} \in \{1,2,3\}$ the set 
            \\[0.2cm]
            \hspace*{1.3cm}
            \texttt{\{ State[row][col] : row in [1..3]\}} 
            \\[0.2cm]
            forms a vertical line. 
      \item Given that the top row is indexed with 1, and the bottom row is row number 3, the set
            \\[0.2cm]
            \hspace*{1.3cm}
            \texttt{\{ State[idx][idx] : idx in [1..3] \}};
            \\[0.2cm]
            is the falling diagonal.
      \item Finally, the set
            \\[0.2cm]
            \hspace*{1.3cm}
            \texttt{\{ State[idx][n - (idx - 1) ] : idx in [1..3] \}}
            \\[0.2cm]
            is the rising diagonal.
      \end{enumerate}
\item The procedure $\texttt{finished}$ takes a $\texttt{State}$ and checks whether the game is finished.
      To this end it computes the $\texttt{utility}$ of the state for the player ``$\texttt{X}$''.  
      If this $\texttt{utility}$ is different from $\Omega$, the game is finished.  Note that it does make no
      difference whether we take the utility of the state for the player ``$\texttt{X}$'' or for the player
      ``$\texttt{O}$'': If the game is finished for  ``$\texttt{X}$'', then it is also finished for ``$\texttt{O}$'' and vice versa.
\end{enumerate}

\section{The Minimax Algorithm}
Having defined the notion of a game, our next task is to come up with an algorithm that can play a game.  The
easiest algorithm that works is the \href{https://en.wikipedia.org/wiki/Minimax}{minimax algorithm}.  This
algorithm is based on the notion of the \blue{value} of a state.  To this end, we define a function
\\[0.2cm]
\hspace*{1.3cm}
$\texttt{value}: \texttt{States} \times \texttt{Players} \rightarrow \{-1, 0, +1\}$
\\[0.2cm]
that takes a state $s \in \texttt{States}$ and a player $p \in \texttt{Players}$ and returns the value of $s$ provided both the player $p$ and his
opponent play \blue{optimally}.  The easiest way to define this function is via recursion.  The base case is simple:
\\[0.2cm]
\hspace*{1.3cm}
$\texttt{finished}(s) \rightarrow \texttt{value}(s, p) = \texttt{utility}(s, p)$.
\\[0.2cm]
If the game is not yet finished, assume that player $o$ is the opponent of player $p$.  Then we define
\\[0.2cm]
\hspace*{1.3cm}
$\neg \texttt{finished}(s) \rightarrow 
 \texttt{value}(s, p) = \max\bigl(\bigl\{
                     -\texttt{value}(n, o) \mid n \in \texttt{nextStates}(s, p)
                     \bigr\}\bigr)
$.
\\[0.2cm]
The reason is that, if the game is not finished yet, the player $p$ has to evaluate all possible moves.  
From these, the player $p$ will choose the move that maximizes the value of the game.  In order to do so, the
player $p$ computes the set 
$\texttt{nextStates}(s, p)$ of all states that can be reached from the state $s$ in any one move of the player $p$.
Now if $n$ is a state that results from player $p$ making some move, then it is the turn of the other player
$o$ to make a move.  Hence, in order to evaluate the state $n$, we have to call the function $\texttt{value}$
recursively as $\texttt{value}(n,o)$.   Since the gains of the other player $o$ are the losses of the player
$p$, we have to take the negative of  $\texttt{value}(n, o)$.
\myFig{game.stlx} shows an implementation of this strategy.


\begin{figure}[!ht]
\centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  firstnumber   = 1,
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.0cm,
                  xrightmargin  = 0.0cm,
                ]
    other := p |-> ([o : o in players() | o != p])[1];
    value := cachedProcedure(State, player) {  // dynamic programming
        if (finished(State)) {
            return utility(State, player);
        }
        return max({-value(ns,other(player)):ns in nextStates(State,player)});
    };
    best_move := procedure(State, player) {
        NS      := nextStates(State, player);
        bestVal := value(State, player);
        return [bestVal, rnd({ns:ns in NS|-value(ns,other(player))==bestVal})];
    };
    play_game := procedure() {
        State := startState();
        print(stateToString(State));
        while (true) {
            firstPlayer  := players()[1];
            [val, State] := best_move(State, firstPlayer);
            print("For me, the game has the value $val$. My move:");
            print(stateToString(State));
            if (final_msg(State)) { return; }
            State := getMove(State);
            print(stateToString(State));
            if (final_msg(State)) { return; }
        }
    };
\end{Verbatim}
\vspace*{-0.3cm}
\caption{The Minimax algorithm.}
\label{fig:game.stlx}
\end{figure}
\begin{enumerate}
\item Given a player $\texttt{p}$, the function $\texttt{other}$ computes the other player,
      which is the first element of the list of all players that are different from $p$.
      This works because we assume that there are just two players.  Therefore the list of all players
      different from the player $\texttt{p}$ contains exactly one element.
\item The implementation of the function $\texttt{value}$ follows the reasoning outlined above.
      However, note that we have implemented the function $\texttt{value}$ as a $\texttt{cachedProcedure}$, i.e.~as a
      procedure that \blue{memorizes} its results.  Hence, when the function $\texttt{value}$ is called a
      second time with the same pair of arguments, it does not recompute the value but rather the value is
      looked up in a so called \blue{cache} that stores all previous results computed by the function $\texttt{value}$.  To
      understand why this is important, 
      let us consider how many states would be explored in the case of tic-tac-toe if we would not use the idea
      of memorizing previous results, a technique which is know as 
      \href{https://en.wikipedia.org/wiki/Memoization}{memoization}.  In this case, we have 9 moves for player
      \texttt{X} from the start state, then 8 moves for player \texttt{O}, then again 7 moves for
      player \texttt{O}.  If we disregard the fact that some games are decided after fewer than 9 moves,
      the function $\texttt{value}$ needs to consider 
      \\[0.2cm]
      \hspace*{1.3cm}
      $9 \cdot 8 \cdot 7 \cdot {\dots} \cdot 2 \cdot 1 = 9! = 362\,880$
      \\[0.2cm]
      moves.  However, if we count the number of possibilities of putting 5 ``\texttt{O}''s and 4
      ``\texttt{X}''s on a $3 \times 3$ board, we see that there are only
      \\[0.2cm]
      \hspace*{1.3cm}
      $\ds {9 \choose 5} = \frac{9!}{5! \cdot 4!} = 126$
      \\[0.2cm]
      possibilities, because we only have to count the number of ways to put 5 ``\texttt{O}''s on
      9 positions and that number is the same as the number of subsets of five elements from a set of nine elements.
      Therefore, if we disregard the fact that some games are decided after fewer than nine moves,  there are a
      factor of $5! \cdot 4! = 2880$ less terminal states to evaluate if we use memoization!

      As we have to evaluate not just terminal states but all states, the saving is actually a bit smaller that
      2880.  The next exercise explores this in more detail.
\item The function $\texttt{best\_move}$ takes a $\texttt{State}$ and a $\texttt{player}$ and returns a pair $\pair(v,s)$
      where $s$ is a state that is optimal for the $\texttt{player}$ and such that $s$ can be reached in one step from
      $\texttt{State}$.  Furthermore, $v$ is the value of this state.
      \begin{enumerate}[(a)]
      \item To this end, it first computes the set $\texttt{NS}$ of all states that can be reached 
            from the given $\texttt{State}$ in one step if $\texttt{player}$ is to move next.
      \item $\texttt{bestValue}$ is the best value that $\texttt{player}$ can achieve in the given $\texttt{State}$.
      \item The function returns randomly one of those states $\texttt{ns} \in \texttt{NS}$ such that 
            the value of $\texttt{ns}$ is optimal, i.e.~is equal to $\texttt{bestValue}$.
            We use randomization here since we want to have more interesting games.  If we would always choose
            the first state that achieves the best value, then our program would always make the same move in
            a given state.  Hence, playing the program would get boring much sooner.
      \end{enumerate}
\item The function $\texttt{play\_game}$ is used to play a game.
      \begin{enumerate}
      \item Initially, $\texttt{State}$ is the $\texttt{startState}$.
      \item As long as the game is not finished, the procedure keeps running.
      \item We compute the player \texttt{firstPlayer} that starts the game and assume that the computer goes first.
            Hence, the function $\texttt{best\_move}$ is used to compute the state that results from the best
            move of $\texttt{firstPlayer}$.
      \item After that, it is checked whether the game is finished.
      \item If the game is not  yet finished, the user is asked to make its move via the function
            $\texttt{getMove}$ that takes a $\texttt{State}$, displays it, and asks the user to enter a move.
            The state resulting from this move is then returned and displayed.

            Note that we do not check the legality of the move entered by the user.  This feature can be used
            for exploration and cheating.
      \item Next, we have to check whether the game is finished after the  move of the user has been executed.
      \item The \texttt{while}-loop keeps iterating until the game is finished.
            We do not have to put a test into the condition of this \texttt{while}-loop as we call the function
            $\texttt{final\_msg}(\texttt{State})$ every time that a new $\texttt{State}$ has been reached.
            This function returns $\texttt{true}$ iff $\texttt{finished}(\texttt{State})$ is true.
            Additionally, it prints a message when the game has finished.
      \end{enumerate}
\end{enumerate}
In order to better understand the reason for using memoization in the implementation of the function
\texttt{value} we introduce the following notions.
\begin{Definition}[\blue{Game Tree}]
  Assume that
  \\[0.2cm]
  \hspace*{1.3cm}
  $\mathcal{G} = \langle \texttt{States}, s_0, \texttt{Players}, \texttt{nextStates}, \texttt{finished},\texttt{utility} \rangle$
  \\[0.2cm]
  is a game. Then a \blue{play of length $n$} is a list of states of the form 
  \\[0.2cm]
  \hspace*{1.3cm}
  $[s_0, s_1, \cdots, s_n]$ \quad such that \quad $\forall i\in\{0,\cdots,n-1\}: s_{i+1} \in \texttt{nextStates}(s_i, p_i)$,
  \\[0.2cm]
  where the players $p_i$ are defined such that for all even $i\in\{0,\cdots,n-1\}$ we have that $p_i$ is the
  first element in the list $\texttt{Players}$, while $p_i$ is the second element otherwise.
  The \blue{game tree} of the game $\mathcal{G}$ is the set of all possible plays.  \eoxs
\end{Definition}

\noindent
The following exercise yields a better understanding of the effects of memoization.

\exercise
In \blue{simplified tic-tac-toe} the game only ends when there are no more empty squares left.
The player \texttt{X} wins if she has more rows, columns, or diagonals of three \texttt{X}s than the player
\texttt{O} has rows, columns, or diagonals of three \texttt{O}s.  Similarly, the player \texttt{O} wins
if he has more rows, columns, or diagonals of three \texttt{O}s than the player \texttt{X} has rows, columns,
or diagonals of three \texttt{X}s.  Otherwise, the game is a draw. 
\begin{enumerate}[(a)]
\item Derive a formula that gives the number of all states of simplified tic-tac-toe.  

      \textbf{Notice} that this question does not ask for the number of all terminal states but rather asks for
      all states. 
\item Write a short program to evaluate the formula derived in part (a) of this exercise.
\item Derive a formula to compute the size of the game tree of simplified tic-tac-toe.
\item Write a short program to evaluate the formula derived in part (c) of this exercise.
\end{enumerate}

\section{$\alpha$-$\beta$-Pruning}
The efficiency of the minimax algorithm can be improved if we provide two additional arguments to the function
$\texttt{value}$.  Traditionally, these arguments are called $\alpha$ and $\beta$.  In order to be able to
distinguish between the old function $\texttt{value}$ and its improved version, we call the improved version 
$\texttt{alphaBeta}$.  The idea is that the function $\texttt{alphaBeta}$ and the function $\texttt{value}$ are
related by the following requirements: 
\begin{enumerate}
\item As long as $\texttt{value}(s, p)$ is between $\alpha$ and $\beta$, the function
      $\texttt{alphaBeta}$ computes the same result as the function $\texttt{value}$,
      i.e.~we have
      \\[0.2cm]
      \hspace*{0.3cm}
      $\alpha \leq \texttt{value}(s, p) \leq \beta \;\rightarrow\;
         \texttt{alphaBeta}(s, p, \alpha, \beta) = \texttt{value}(s,p)
      $.
\item If $\texttt{value}(s, p) \leq \alpha$, we require that the value returned by
      $\texttt{alphaBeta}$ is less than or equal to $\alpha$, i.e.~we have 
      \\[0.2cm]
      \hspace*{0.3cm}
      $\texttt{value}(s, p) \leq \alpha \;\rightarrow\; \texttt{alphaBeta}(s, p, \alpha, \beta) \leq \alpha$.
\item Similarly, if $\texttt{value}(s, p) \geq \beta$, we require that the value
      returned by $\texttt{valueAlphaBeta}$ is bigger than or equal to $\beta$, i.e.~we have 
      \\[0.2cm]
      \hspace*{0.3cm}
      $\beta \leq \texttt{value}(s, p) \;\rightarrow\; \beta \leq \texttt{alphaBeta}(s, p, \alpha, \beta)$.
\end{enumerate}
Therefore, $\texttt{alphaBeta}(\texttt{State}, \texttt{player})$  is only an approximation of
$\texttt{value}(\texttt{State}, \texttt{player})$.  However, it turns out that this approximation is all that
is needed.  \myFig{game-alpha-beta.stlx} shows an implementation of $\texttt{alphaBeta}$ that achieves this
specification.  Once the function $\texttt{alphaBeta}$ is implemented, the function $\texttt{value}$ can then
be realized as follows: 
\\[0.2cm]
\hspace*{1.3cm}
$\texttt{value}(s, p ) := \texttt{alphaBeta}(s, p, -1, +1)$.
\\[0.2cm]
The reason is that we already know that $-1 \leq \texttt{value}(s,p) \leq +1$ and hence the first case of the
specification of $\texttt{alphaBeta}$ guarantees that the equation
\\[0.2cm]
\hspace*{1.3cm}
$\texttt{value}(s,p) = \texttt{alphaBeta}(s,p,-1,+1)$
\\[0.2cm]
holds.  Since $\texttt{alphaBeta}$ is implemented as a recursive procedure, 
the fact that the implementation of $\texttt{alphaBeta}$ shown in \myFig{game-alpha-beta.stlx} satisfies the
specification given above can be shown by computational induction.  


\begin{figure}[!ht]
\centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  firstnumber   = 1,
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.0cm,
                  xrightmargin  = 0.0cm,
                ]
    alphaBeta := cachedProcedure(State, player, alpha := -1, beta := 1) {
        if (finished(State)) {
            return utility(State, player);
        }
        val := alpha;
        for (ns in nextStates(State, player)) {
            val := max({ val, -value(ns, other(player), -beta, -val) });
            if (val >= beta) {
                return val;
            }
            alpha := max({ val, alpha });
        }
        return val;
    };
\end{Verbatim}
\vspace*{-0.3cm}
\caption{$\alpha$-$\beta$-Pruning.}
\label{fig:game-alpha-beta.stlx}
\end{figure}

We proceed to discuss the implementation of the function $\texttt{alphaBeta}$.
\begin{enumerate}
\item If $\texttt{State}$ is a terminal state, the function returns the $\texttt{utility}$ of the given
      $\texttt{State}$ with respect to $\texttt{player}$.
\item The variable $\texttt{val}$ is supposed to store the maximum of the values of all states
      that can be reached from the given $\texttt{State}$ if $\texttt{player}$ makes one move.
      
      According to the specification of $\texttt{alphaBeta}$,  we are not interested in values that are below
      $\alpha$.  Hence, it suffices to initialize $\texttt{val}$ with $\alpha$.   This way, in the case that we have
      \\[0.2cm]
      \hspace*{1.3cm}
      $\texttt{value}(\texttt{State},\texttt{player}) < \alpha$,
      \\[0.2cm]
      instead of returning the true value of the given $\texttt{State}$, the function
      $\texttt{alphaBeta}(\texttt{State},\texttt{player},\alpha,\beta)$ will instead return the value $\alpha$, which is permitted by its specification.
\item Next, we iterate over all successor states $\texttt{ns} \in \texttt{nextStates}(\texttt{State}, \texttt{player})$.
\item We have to recursively evaluate the states $\texttt{ns}$ for the $\texttt{other}$ player.
      Since the value of a state for the $\texttt{other}$ player is the negative of the value for
      $\texttt{player}$, we have to exchange the roles of $\alpha$ and $\beta$ and prefix them with a negative
      sign.

      Note that the value of $\texttt{val}$ computed in the previous iteration of the \texttt{for}-loop 
      can serve as the value of the parameter $\alpha$ for the next recursive call, since once we have found a 
      state that has value $\texttt{val}$, we know already that $\texttt{value}(s,p)$ is at least
      $\texttt{val}$.  Therefore,  if we encounter states with a value
      less than $\texttt{val}$ during our recursive evaluation of the states reachable from $\texttt{State}$,
      then those states can be ignored.   This is achieved by using $\texttt{-val}$ for the parameter $\beta$.
\item As the specification of $\texttt{alphaBeta}$ ask us to compute the value of $\texttt{State}$ only in
      those cases where it is less than or equal to $\beta$, once we find a successor state $s$ that has a
      value that is at least as big a $\beta$ we can stop the evaluation and return this value.

      \blue{In practice, this shortcut results in significant savings of computation time!}
\end{enumerate}

\exercise
Prove that for any state $s$ and player $p$ we have
\\[0.2cm]
\hspace*{1.3cm}
$\texttt{alphaBeta}(s, p, -1, 1) = \texttt{value}(s, p)$.
\\[0.2cm]
\textbf{Hint}:  This claim is best shown using \blue{computational induction}.
\eox

\section{Depth Limited Search}
In practice, most games are far too complex to be evaluated completely, i.e.~the size of the set
$\texttt{States}$ is so big that even the fastest computer does not stand a chance to explore this set
completely.  For example, it is impossible to consider all possible states in chess.  Instead, we have to limit
the exploration in a way that is similar to the way professional players evaluate their game:  Usually, a
player considers all variations of the game for, say, the next three moves.  After a given number of moves, the
value of a position is estimated using an evaluation function.  In order to implement this idea, we add a
parameter $\texttt{limit}$ to the procedure $\texttt{value}$.  On every recursive invocation 
of the function $\texttt{value}$, the function $\texttt{limit}$ is decreased.  Once the limit reaches $0$,
instead of invoking the function $\texttt{value}$ again recursively, we try to estimate the value of
the given $\texttt{State}$ using a \blue{heuristic function}.  This leads to the code shown in \myFig{game-limit.stlx}.


\begin{figure}[!ht]
\centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  firstnumber   = 1,
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.0cm,
                  xrightmargin  = 0.0cm,
                ]
    value := cachedProcedure(State, player, limit, alpha := -1, beta := 1) {
        if (finished(State)) {
            return utility(State, player);
        }
        if (limit == 0) { return heuristic(State, player); }
        other := arb(players() - { player });
        val   := alpha;
        for (ns in nextStates(State, player)) {
            val := max({ val, -value(ns, other, limit - 1, -beta, -val) });
            if (val >= beta) {
                return val;
             }
             alpha := max({ val, alpha });             
        }
        return val;
    };
\end{Verbatim}
\vspace*{-0.3cm}
\caption{Depth-limited $\alpha$-$\beta$-pruning.}
\label{fig:game-limit.stlx}
\end{figure}
For a game like tic-tac-toe it is difficult to come up with a decent heuristic.  A very crude approach would be
to define:
\\[0.2cm]
\hspace*{1.3cm}
\texttt{heuristic := [State, player] |-> 0;}
\\[0.2cm]
This heuristic would simply estimate the value of all states to be $0$.  As this heuristic is only called after
it has been tested that the game has not yet been decided, this approach is not utterly unreasonable.  For a more
complex game like chess, the heuristic could instead be a \blue{weighted count} of all pieces.  Concretely, the
algorithm for estimating the value of a state would work as follows:
\begin{enumerate}
\item Initially, the variable $\texttt{sum}$ is set to $0$:
      \\[0.2cm]
      \hspace*{1.3cm}
      \texttt{sum := 0;}
\item We would count the number of white rooks $\texttt{Rook}_{\mathrm{white}}$ and black rooks $\texttt{Rook}_{\mathrm{black}}$,
      subtract these numbers from each other and multiply the difference by $5$.  
      The resulting number would be added to $\texttt{sum}$:
      \\[0.2cm]
      \hspace*{1.3cm}
      $\texttt{sum} \;\texttt{+=}\; (\texttt{Rook}_{\mathrm{white}} - \texttt{Rook}_{\mathrm{black}}) \cdot 5\texttt{;}$
\item We would count the number of white bishops $\texttt{Bishop}_{\mathrm{white}}$ and black bishops
      $\texttt{Bishop}_{\mathrm{black}}$,
      subtract these numbers from each other and multiply the difference by $3$.  
      The resulting number would be added to $\texttt{sum}$:
      \\[0.2cm]
      \hspace*{1.3cm}
      $\texttt{sum} \;\texttt{+=}\; (\texttt{Bishop}_{\mathrm{white}} - \texttt{Bishop}_{\mathrm{black}}) \cdot 3\texttt{;}$
\item In a similar way we would count knights, queens, and pawns.  Approximately, the weights of
      knights are $3$, a queen is worth $9$ and a pawn is worth $1$.
\end{enumerate}
The resulting $\texttt{sum}$ can then be used as an approximation of the value of a state.
More details about the weights of the pieces can be found in the Wikipedia article 
``\href{https://en.wikipedia.org/wiki/Chess_piece_relative_value}{chess piece relative value}''.



\exercise
Read up on the game \href{https://en.wikipedia.org/wiki/Connect_Four}{Connect Four}.  You can play it online at
\\[0.2cm]
\hspace*{1.3cm}
\href{http://www.4-gewinnt.de}{\texttt{http://www.4-gewinnt.de}}
\\[0.2cm]
Your task is to implement this game.  At the address
\\[0.2cm]
\hspace*{1.3cm}
\href{https://github.com/karlstroetmann/Artificial-Intelligence/blob/master/SetlX/connect-four-frame.stlx}{https://github.com/karlstroetmann/Artificial-Intelligence/blob/master/SetlX/connect-four-frame.stlx}
\\[0.2cm]
is a frame that can be used to solve this exercise.  In this frame, only the following procedures need to be
implemented. 
\begin{enumerate}
\item The procedure $\texttt{nextStates}(s, p)$ is called with a state $s$ and a player $p$.
      It is supposed to return the set of all states that can be reached from the given state $s$ if player $p$
      is next to make a move.  In order to implement this function efficiently, you should make use of the
      function $\texttt{find\_empty}$ that is described below.  
\item The procedure $\texttt{find\_empty}(s, c)$ is called with a state $s$ and a column $c$.  It searches the
      column $c$ of the board specified by $s$ bottom up for the first empty square.  Once an empty square is found, 
      the corresponding row is returned.  If all the squares in the column $c$ are filled, then the number $7$
      is returned instead.
\item The procedure $\texttt{utility}(s, p)$ is called with a state $s$ and a player $p$.
      It computes the utility that this state has for player $p$ if player $p$ is the next to move.
      For efficiency reasons, the implementation of $\texttt{utility}$ should make use of the auxiliary functions
      $\texttt{all\_lines}$ and $\texttt{last\_line\_filled}$ that are described below.
\item The procedure $\texttt{all\_lines}()$ takes no arguments.  It is supposed to compute all sets of coordinates that form
      a line of four consecutive squares.  For example, one such set would be the set
      \\[0.2cm]
      \hspace*{1.3cm}
      $\{ \pair(1,1), \pair(1,2), \pair(1,3), \pair(1,4) \}$.
      \\[0.2cm]
      This set would be the vertical line that starts at $\pair(1,1)$.  The horizontal line that starts at the
      location  $\pair(1,1)$ is the set
      \\[0.2cm]
      \hspace*{1.3cm}
      $\{ \pair(1,1), \pair(2,1), \pair(3,1), \pair(4,1) \}$,
      \\[0.2cm]
      while the rising diagonal starting at $\pair(1,1)$ is represented by the set
      \\[0.2cm]
      \hspace*{1.3cm}
      $\{ \pair(1,1), \pair(2,2), \pair(3,3), \pair(4,4) \}$.
      \\[0.2cm]
      Note that the procedure $\texttt{all\_lines}$ should be implemented as a \texttt{cachedProcedure}.  This
      way it is guaranteed that the necessary computation is only performed once.
\item The procedure $\texttt{last\_line\_filled}(s)$ takes a state $s$.  It checks whether the game is drawn.
      The game is drawn iff the board is completely filled.  This can be checked most efficiently by checking
      the final row of the board.  If this row is completely filled, all other rows must have  been filled, too.
      \eox
\end{enumerate}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "artificial-intelligence"
%%% End:
