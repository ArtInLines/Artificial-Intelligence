\chapter{Introduction}

\section{What is Artificial Intelligence?}
Before we start to dive into the subject of
\href{https://en.wikipedia.org/wiki/Artificial_intelligence}{Artificial Intelligence} (usually abbreviated as
\ac{ai}) we have to answer the following question:  
\\[0.2cm]
\hspace*{1.3cm}
What is \blue{artificial intelligence}? 
\\[0.2cm] 
According to the Oxford Dictionary of English,
\index{artificial intelligence, definition}
artificial intelligence is:
\begin{quote}
  \colorbox{sepia}{\textsl{The theory and development of computer systems able to perform tasks normally}} \linebreak
  \colorbox{sepia}{\textsl{requiring human intelligence, such as visual perception, speech recognition,}}  \linebreak
  \colorbox{sepia}{\textsl{decision-making, and translation between languages.}} 
\end{quote}
There have been two competitive approaches to machine learning.  The first approach is based on
\blue{symbolic logic} and is known as \blue{symbolic AI}.  \index{symbolic AI}
Typical tasks addressed with this approach were the development of automatic theorem provers, programs to
perform \blue{symbolic integration}, or programs to play chess like
\href{https://en.wikipedia.org/wiki/Deep_Blue_(chess_computer)}{Deep Blue}.
In the beginning, this approach was the dominant paradigm in AI.
The second approach is known as \blue{machine learning}.  Arthur Samuel defined machine learning as
``the field of study that gives computers the ability to learn without being
explicitly programmed'' \cite{samuel:1959}. \index{machine learning, definition}
Machine learning is mostly responsible for the recent hype in AI.

\section{Overview}
This lecture consists of two parts.
\begin{enumerate}
\item The common theme of the first part is \blue{declarative programming}.  This approach is part of symbolic
      AI.  The main idea of declarative 
      programming is that we start with a \blue{problem specification}.  This is usually a short description of
      the problem that is to be solved.  This description is then fed into an \blue{automatic problem solver}
      that returns a solution of the problem.  Originally, 
      \href{https://en.wikipedia.org/wiki/Declarative_programming}{declarative programming} was a very general
      approach to problem solving.  The idea was that in order to solve a problem, the problem would first be
      formulated as a logic formula and an
      \href{https://en.wikipedia.org/wiki/Automated_theorem_proving}{automated theorem prover} would then be
      able to solve the problem.  Unfortunately, in this generality the idea of declarative programming has
      turned out to be unsuitable for real world problems for two reasons:
      \begin{enumerate}
      \item First, it is very difficult to specify practical problems completely in a logical framework.
      \item Second, even in those cases where a complete logic based specification of a problem is feasible,
            automatic theorem proving is generally not powerful enough to find a solution automatically. 
      \end{enumerate}
      However, there are a number of domains where the approach of declarative programming has turned out to be
      useful.  In particular, we show how declarative programming can be used to solve problems in the
      following domains.
      \begin{enumerate}
      \item \blue{Search problems} are problems where the task is to find a path in a graph.  A typical example of a
            search problem is the \href{https://en.wikipedia.org/wiki/15_puzzle}{fifteen puzzle}.
            We discuss various state-of-the-art algorithms that can solve search problems.
      \item \blue{Games} like \href{https://en.wikipedia.org/wiki/Chess}{chess} or
            \href{https://en.wikipedia.org/wiki/checkers}{checkers} can be specified quite easily and there are
            various techniques for computers to find optimal strategies for playing adversarial games.
      \item \href{https://en.wikipedia.org/wiki/Constraint_satisfaction_problem}{Constraint satisfaction problems} 
            have great practical importance.  Today, very efficient constraint solvers have been developed to
            solve various constraint satisfaction problems that occur in practice.
      \end{enumerate}
\item In the second part of this lecture we discuss \blue{machine learning}.  In the last ten years, a number of
      advances in machine learning have made it into the headlines of the news.  It is fair to say that
      currently machine learning is the hottest topic in computer science.  Among others, we discuss the following
      algorithms:
      \begin{enumerate}
      \item \blue{Linear regression} is one of the most fundamental machine learning algorithms.
            In machine learning, we are given a number of data pairs of the form  $\langle \mathbf{x}_i, y_i \rangle$ 
            where $i \in \{1,\cdots,N\}$ and for all $i \in \{1,\cdots,N\}$ we have $\mathbf{x}_i \in \mathbb{R}^m$
            and $y_i \in \mathbb{R}$.  We assume that there is an unknown function $f:\mathbb{R}^m \rightarrow \mathbb{R}$
            such that $y_i \approx f(\mathbf{x}_i)$.  Our task is to find an approximation for the function
            $f$.  When using linear regression, we assume that the function $f$ is linear in its arguments.
            Although this sounds like a strong assumption, we will see that linear regression is surprisingly
            powerful in practice.
      \item In a \blue{classification problem} we again have $N$ pairs of the form $\langle \mathbf{x}_i, y_i
        \rangle$.
            As before,  we have $\mathbf{x}_i \in \mathbb{R}^m$, but now $y_i \in \mathbb{B}$, where
            $\mathbb{B}$ is the set of Boolean values, i.e.~we have $\mathbb{B} = \{\mathtt{true}, \mathtt{false}\}$.
            The task is then to find a function $f:\mathbb{R}^m \rightarrow \mathbb{B}$
            such that the equation $y_i = f(\mathbf{x}_i)$ is true for most $i\in\{1,\cdots,N\}$.  A typical
            classification problem is \href{https://en.wikipedia.org/wiki/Email_spam}{spam detection}.  The
            first algorithm we introduce to solve classification problems is \blue{logistic regression}.
            After that, we study \blue{support vector machines} and \blue{naive Bayes classifiers}.
      \item Finally, we discuss neural networks.  As an example, we will build a neural network that is able to
            recognize digits. 
      \end{enumerate}
\end{enumerate}
\pagebreak

\section{Literature}
The main sources of these lecture notes are the following:
\begin{enumerate}
\item A course on artificial intelligence that was offered on the \textsc{edX} platform.  The course
      materials are available at  
      \\[0.2cm]
      \hspace*{1.3cm}
      \href{http://ai.berkeley.edu/home.html}{http://ai.berkeley.edu/home.html}.
\item The book
      \\[0.2cm]
      \hspace*{1.3cm}
      \href{http://www.google.com/search?q=introduction+to+Artificial+Intelligence+RusseLl+Norvig+pdf}{Introduction to Artificial Intelligence}
      \\[0.2cm]
      written by Stuart Russell and Peter Norvig \cite{russell:2009}.
\item A course on artificial intelligence that is offered on \href{https://www.udacity.com}{Udacity}.  The title of the
      course is
      \\[0.2cm]
      \hspace*{1.3cm}
      \href{https://www.udacity.com/course/intro-to-artificial-intelligence--cs271}{Intro to Artificial Intelligence}
      \\[0.2cm]
      and the course is given by \href{https://en.wikipedia.org/wiki/Peter_Norvig}{Peter Norvig}, who is
      director of research at Google and \href{https://en.wikipedia.org/wiki/Sebastian_Thrun}{Sebastian Thrun},
      who is the chairman of \href{https://www.udacity.com}{Udacity}.
\end{enumerate}
The programs presented in these lecture notes are expected to run with version 3.7 of \textsl{Python}.


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "artificial-intelligence"
%%% End:
