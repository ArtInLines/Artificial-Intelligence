{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab56590",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "with open (\"../style.css\", \"r\") as file:\n",
    "    css = file.read()\n",
    "HTML(css)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7958f8b",
   "metadata": {},
   "source": [
    "# Automatic Differentiation with `autograd`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51c54e0",
   "metadata": {},
   "source": [
    "Technically, `autograd` is layer that wraps and extends `numpy`.  Hence it is most often imported as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4544c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd\n",
    "import autograd.numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3995a3b0",
   "metadata": {},
   "source": [
    "The function `sigmoid` implements the [sigmoid function](https://en.wikipedia.org/wiki/Sigmoid_function), which is defined as\n",
    "$$ \\texttt{S}(x) = \\frac{1}{1 + \\mathrm{e}^{-x}}. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615b3208",
   "metadata": {},
   "outputs": [],
   "source": [
    "def S(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7731595e",
   "metadata": {},
   "source": [
    "The function `Q(x)` computes the square of `x`, i.e. we have \n",
    "$$ Q(x) = x^2. $$\n",
    "Of course, the derivate of $x^2$ is just $2\\cdot x$, i.e. we have\n",
    "$$ \\frac{\\mathrm{d} Q}{\\mathrm{d} x} = 2 \\cdot x. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5236f013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q(x):\n",
    "    return np.multiply(x, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c55c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_grad = autograd.grad(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0f59ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_grad(1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7c855e",
   "metadata": {},
   "source": [
    "The function `S_prime` computes the [derivative](https://en.wikipedia.org/wiki/Derivative) of the Sigmoid function.  We implement it using *automatic differentiation*.  This is the closest thing to magic I have seen yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a3f134",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_prime = autograd.grad(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2405b7ee",
   "metadata": {},
   "source": [
    "In the lecture we have seen that the following identity holds for the derivative of the sigmoid function:\n",
    "$$ S'(x) = S(x) \\cdot \\bigl(1 - S(x)\\bigr) $$\n",
    "Let's test this identity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf246b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in np.arange(-2.0, 2.0, 0.1):\n",
    "    print(S_prime(x)- S(x) * (1.0 - S(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cdea58",
   "metadata": {},
   "source": [
    "The identity seems to hold up to rounding errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220a4fab",
   "metadata": {},
   "source": [
    "The cool thing about `autograd` is that it can take the derivative of a Python function.\n",
    "The function `mySqrt(x)` computes the square root of `x` using [Newton's method](https://en.wikipedia.org/wiki/Newton%27s_method)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aeb4b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mySqrt(x): \n",
    "    root = 1.0\n",
    "    eps  = 2.0e-15\n",
    "    while abs(x - root * root) > eps:\n",
    "        root = 0.5 * (root + x / root)    \n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410b32b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "[mySqrt(n)  for n in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8fdb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mySqrtGrad = autograd.grad(mySqrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50d7947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rnd\n",
    "rnd.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea76b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd.random()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c271cf",
   "metadata": {},
   "source": [
    "As we have\n",
    "$$ \\frac{\\mathrm{d}\\; }{\\mathrm{d} x}\\sqrt{x} = \\frac{1}{2} \\cdot \\frac{1}{\\sqrt{x}}, $$\n",
    "we expect the following loop to not return any errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a7807e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(1000):\n",
    "    x = rnd.random()\n",
    "    error = mySqrtGrad(x) - 0.5 / mySqrt(x)\n",
    "    if error > 1.0e-15:\n",
    "        print(error, x, mySqrt(x), mySqrtGrad(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844acbf0",
   "metadata": {},
   "source": [
    "Unfortunately, `autograd` has its limitations, as shown by the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7034d61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mySqrtGrad(1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d76e30",
   "metadata": {},
   "source": [
    "We can fix this bug by rewriting the function `mySqrt`.  The problem with the old implementation was that we returned a constant value in the case that $x = 1.0$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2795f29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mySqrt(x): \n",
    "    root = 0.5 * x\n",
    "    eps  = 2.0e-15\n",
    "    while abs(x - root * root) > eps:\n",
    "        root = 0.5 * (root + x / root)    \n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6862c965",
   "metadata": {},
   "outputs": [],
   "source": [
    "mySqrtGrad = autograd.grad(mySqrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfefaa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mySqrtGrad(1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e14bde",
   "metadata": {},
   "source": [
    "## Implementing Newton's Method with `autograd`\n",
    "\n",
    "[Newton's method](https://en.wikipedia.org/wiki/Newton%27s_method) for solving an equation of the form\n",
    "$$  f(x) = 0 $$\n",
    "defines a sequence $(x_n)_{n\\in\\mathbb{N}}$ inductively:\n",
    "* $x_0 = 1.0$\n",
    "* $x_{n+1} = x_n - \\frac{\\displaystyle f(x_n)}{\\displaystyle f'(x_n)}$  \n",
    " \n",
    "Then, if the function $f$ is convex and twice differentiable, the limit \n",
    "$$ \\bar{x} = \\lim\\limits_{n\\rightarrow\\infty} x_n $$\n",
    "satisfies $f(\\bar{x}) = 0$.\n",
    "\n",
    "The function `newton` takes a function `f` and its derivative `fs` and computes the \n",
    "value `x` such that $f(x) = 0$ using Newton's method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfc0b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton(f):\n",
    "    fs = autograd.grad(f)\n",
    "    x = 1.0 \n",
    "    eps = 1.0e-14\n",
    "    while abs(f(x)) > eps:\n",
    "        x = x - f(x) / fs(x)\n",
    "        print(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3013091a",
   "metadata": {},
   "source": [
    "We proceed to solve the equation\n",
    "$$ \\cos(x) - x = 0. $$\n",
    "To this end we define the function $f(x) = \\cos(x) - x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfd3546",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x): \n",
    "    return np.cos(x) - x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf0d179",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = newton(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b09269a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.cos(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c0a3a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
