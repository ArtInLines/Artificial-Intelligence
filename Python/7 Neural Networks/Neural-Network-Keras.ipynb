{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<link href='http://fonts.googleapis.com/css?family=Alegreya+Sans:100,300,400,500,700,800,900,100italic,300italic,400italic,500italic,700italic,800italic,900italic' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Arvo:400,700,400italic' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=PT+Mono' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Shadows+Into+Light' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Philosopher:400,700,400italic,700italic' rel='stylesheet' type='text/css'>\n",
       "\n",
       "<style>\n",
       "\n",
       "@font-face {\n",
       "    font-family: \"Computer Modern\";\n",
       "    src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\n",
       "}\n",
       "\n",
       ".container { width: 100% }\n",
       "\n",
       "/* Formatting for header cells */\n",
       ".text_cell_render h1 {\n",
       "    font-family: 'Philosopher', sans-serif;\n",
       "    font-weight: 400;\n",
       "    font-size: 2.2em;\n",
       "    line-height: 100%;\n",
       "    color: rgb(0, 80, 120);\n",
       "    margin-bottom: 0.1em;\n",
       "    margin-top: 0.1em;\n",
       "    display: block;\n",
       "}\t\n",
       ".text_cell_render h2 {\n",
       "    font-family: 'Philosopher', serif;\n",
       "    font-weight: 400;\n",
       "    font-size: 1.9em;\n",
       "    line-height: 100%;\n",
       "    color: rgb(200,100,0);\n",
       "    margin-bottom: 0.1em;\n",
       "    margin-top: 0.1em;\n",
       "    display: block;\n",
       "}\t\n",
       "\n",
       ".text_cell_render h3 {\n",
       "    font-family: 'Philosopher', serif;\n",
       "    margin-top:12px;\n",
       "    margin-bottom: 3px;\n",
       "    font-style: italic;\n",
       "    color: rgb(94,127,192);\n",
       "}\n",
       "\n",
       ".text_cell_render h4 {\n",
       "    font-family: 'Philosopher', serif;\n",
       "}\n",
       "\n",
       ".text_cell_render h5 {\n",
       "    font-family: 'Alegreya Sans', sans-serif;\n",
       "    font-weight: 300;\n",
       "    font-size: 16pt;\n",
       "    color: grey;\n",
       "    font-style: italic;\n",
       "    margin-bottom: .1em;\n",
       "    margin-top: 0.1em;\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".text_cell_render h6 {\n",
       "    font-family: 'PT Mono', sans-serif;\n",
       "    font-weight: 300;\n",
       "    font-size: 10pt;\n",
       "    color: grey;\n",
       "    margin-bottom: 1px;\n",
       "    margin-top: 1px;\n",
       "}\n",
       "\n",
       ".text_cell_render em {\n",
       "    font-family: 'Philosopher', sans-serif;\n",
       "    color:        blue;\n",
       "    background-color: rgb(255,220,180);\n",
       "    font-size:    110%;\n",
       "    margin-left:   2px;\n",
       "    margin-right:  2px;\n",
       "    font-weight:   100;\n",
       "}\n",
       "\n",
       ".text_cell_render b {\n",
       "    color:            rgb(255,195,195);\n",
       "    background-color: rgb(0,0,0);\n",
       "    font-size:    110%;\n",
       "    margin-left:   2px;\n",
       "    margin-right:  2px;\n",
       "    font-weight:   650;\n",
       "}\n",
       "\n",
       ".text_cell_render u {\n",
       "    color:            blue;\n",
       "    font-size:    110%;\n",
       "    margin-left:   2px;\n",
       "    margin-right:  2px;\n",
       "    font-weight:   650;\n",
       "}\n",
       "\n",
       ".text_cell_render tt {\n",
       "    font-size:    120%;\n",
       "    margin-left:   2px;\n",
       "    margin-right:  2px;\n",
       "    font-weight:   150;\n",
       "}\n",
       "\n",
       ".Codemirror {\n",
       "    font-family: \"PT Mono\";\n",
       "    font-size: 100%;\n",
       "}\n",
       "\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "with open (\"../style.css\", \"r\") as file:\n",
    "    css = file.read()\n",
    "HTML(css)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O6bAYTDQvA9E"
   },
   "source": [
    "# Building a Neural Network with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "Ofc-wXYMESXW",
    "outputId": "5cbd5e88-7833-44b7-ef23-249306c3eb15"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "import numpy  as np\n",
    "import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following magic command is necessary to prevent the Python kernel to die because of linkage problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: KMP_DUPLICATE_LIB_OK=TRUE\n"
     ]
    }
   ],
   "source": [
    "%env KMP_DUPLICATE_LIB_OK=TRUE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function $\\texttt{vectorized_result}(d)$ converts the digit $d \\in \\{0,\\cdots,9\\}$ and returns a NumPy vector $\\mathbf{x}$ of shape $(10, 1)$ such that\n",
    "$$\n",
    "\\mathbf{x}[i] = \n",
    "\\left\\{\n",
    "  \\begin{array}{ll}\n",
    "     1 & \\mbox{if $i = j$;} \\\\\n",
    "     0 & \\mbox{otherwise.}\n",
    "  \\end{array}  \n",
    "\\right.\n",
    "$$\n",
    "This function is used to convert a digit $d$ into the expected output of a neural network that has an output unit for every digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorized_result(d):\n",
    "    e    = np.zeros((10, ), dtype=np.float32)\n",
    "    e[d] = 1.0\n",
    "    return e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function $\\texttt{load_data}()$ returns a pair of the form\n",
    "$$ (\\texttt{training_data}, \\texttt{test_data}) $$\n",
    "where \n",
    "<ul>\n",
    "<li> $\\texttt{training_data}$ is a list containing 60,000 pairs $(\\textbf{x}, \\textbf{y})$ s.t. $\\textbf{x}$ is a 784-dimensional `numpy.ndarray` containing the input image and $\\textbf{y}$ is a 10-dimensional `numpy.ndarray` corresponding to the correct digit for x.</li>\n",
    "<li> $\\texttt{test_data}$ is a list containing 10,000 pairs $(\\textbf{x}, y)$.  In each case, \n",
    "     $\\textbf{x}$ is a 784-dimensional `numpy.ndarry` containing the input image, \n",
    "     and $y$ is the corresponding digit value.\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    with gzip.open('../mnist.pkl.gz', 'rb') as f:\n",
    "        train, validate, test = pickle.load(f, encoding=\"latin1\")\n",
    "    X_train = np.array([np.reshape(x, (784, )) for x in train[0]])\n",
    "    X_test  = np.array([np.reshape(x, (784, )) for x in test [0]])\n",
    "    Y_train = np.array([vectorized_result(y) for y in train[1]])\n",
    "    Y_test  = np.array([vectorized_result(y) for y in test [1]])\n",
    "    return (X_train, X_test, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "Ofc-wXYMESXW",
    "outputId": "5cbd5e88-7833-44b7-ef23-249306c3eb15"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see what we have read:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "Ofc-wXYMESXW",
    "outputId": "5cbd5e88-7833-44b7-ef23-249306c3eb15"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 784), (10000, 784), (50000, 10), (10000, 10))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we create a neural network with two hidden layers.\n",
    "- The first hidden layer has 60 nodes and uses the <a href=\"https://en.wikipedia.org/wiki/Rectifier_(neural_networks)\">ReLU function</a> \n",
    "  as activation function.\n",
    "- The second hidden layer uses 30 nodes and also uses the ReLu function.  \n",
    "- The output layer uses the <a href=\"https://en.wikipedia.org/wiki/Softmax_function\">softmax function</a> as \n",
    "  activation function.  This function is defined as follows:\n",
    "  $$ \\sigma(\\mathbf{z})_i := \\frac{e^{z_i}}{\\sum\\limits_{d=0}^{9} e^{z_d}}  $$\n",
    "  Here, $N$ is the number of output nodes and $z_i$ is the sum of the inputs of the $i$-th output neuron.\n",
    "  This function guarantees that the outputs of the 10 output nodes can be interpreted as probabilities, since \n",
    "  there sum is equal to $1$.\n",
    "- The <em style=\"color:blue\">loss function</em> used is the <em style=\"color:blue\">cross-entropy</em>.  \n",
    "  If a neuron outputs the value $a$, when it should output the value $y \\in \\{0,1\\}$, the cross entropy cost of \n",
    "  this neuron is defined as\n",
    "  $$ C(a, y) := - y \\cdot \\ln(a) - (1-y)\\cdot \\ln(1-a). $$\n",
    "- The cost function is minimzed using stochastic gradient descent with a learning rate of $0.3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17156
    },
    "colab_type": "code",
    "id": "tksxAR3CuorW",
    "outputId": "b80fca9d-5f96-4f51-df34-28cdf5e80f9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 80)                62800     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 40)                3240      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                410       \n",
      "=================================================================\n",
      "Total params: 68,090\n",
      "Trainable params: 68,090\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense( 80, activation='relu', input_dim=784))\n",
    "model.add(keras.layers.Dense( 40, activation='relu'               ))\n",
    "model.add(keras.layers.Dense( 40, activation='relu'               ))\n",
    "model.add(keras.layers.Dense( 10, activation='softmax'            ))\n",
    "model.compile(loss       = 'categorical_crossentropy', \n",
    "              optimizer  = tf.keras.optimizers.SGD(lr=0.3), \n",
    "              metrics    = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17156
    },
    "colab_type": "code",
    "id": "tksxAR3CuorW",
    "outputId": "b80fca9d-5f96-4f51-df34-28cdf5e80f9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.4084 - accuracy: 0.8748 - val_loss: 0.1763 - val_accuracy: 0.9508\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.1439 - accuracy: 0.9557 - val_loss: 0.1265 - val_accuracy: 0.9621\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 2s 38us/step - loss: 0.1035 - accuracy: 0.9684 - val_loss: 0.1056 - val_accuracy: 0.9671\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.0807 - accuracy: 0.9752 - val_loss: 0.0959 - val_accuracy: 0.9713\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 0.0660 - accuracy: 0.9801 - val_loss: 0.1055 - val_accuracy: 0.9691\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 0.0554 - accuracy: 0.9828 - val_loss: 0.1010 - val_accuracy: 0.9703\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 0.0493 - accuracy: 0.9837 - val_loss: 0.1142 - val_accuracy: 0.9669\n",
      "Epoch 8/30\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 0.0420 - accuracy: 0.9864 - val_loss: 0.0933 - val_accuracy: 0.9713\n",
      "Epoch 9/30\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 0.0361 - accuracy: 0.9882 - val_loss: 0.0997 - val_accuracy: 0.9721\n",
      "Epoch 10/30\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 0.0302 - accuracy: 0.9902 - val_loss: 0.1032 - val_accuracy: 0.9744\n",
      "Epoch 11/30\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 0.0265 - accuracy: 0.9913 - val_loss: 0.0946 - val_accuracy: 0.9757\n",
      "Epoch 12/30\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 0.0214 - accuracy: 0.9932 - val_loss: 0.1166 - val_accuracy: 0.9711\n",
      "Epoch 13/30\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 0.0231 - accuracy: 0.9926 - val_loss: 0.1732 - val_accuracy: 0.9586\n",
      "Epoch 14/30\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 0.0354 - accuracy: 0.9893 - val_loss: 0.0993 - val_accuracy: 0.9756\n",
      "Epoch 15/30\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 0.0151 - accuracy: 0.9952 - val_loss: 0.0944 - val_accuracy: 0.9781\n",
      "Epoch 16/30\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 0.0147 - accuracy: 0.9952 - val_loss: 0.0931 - val_accuracy: 0.9798\n",
      "Epoch 17/30\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.1066 - val_accuracy: 0.9765\n",
      "Epoch 18/30\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.1182 - val_accuracy: 0.9747\n",
      "Epoch 19/30\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 0.0196 - accuracy: 0.9946 - val_loss: 0.1028 - val_accuracy: 0.9758\n",
      "Epoch 20/30\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.0086 - accuracy: 0.9971 - val_loss: 0.1055 - val_accuracy: 0.9781\n",
      "Epoch 21/30\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.0135 - accuracy: 0.9956 - val_loss: 0.1194 - val_accuracy: 0.9775\n",
      "Epoch 22/30\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.0078 - accuracy: 0.9975 - val_loss: 0.1115 - val_accuracy: 0.9786\n",
      "Epoch 23/30\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.0089 - accuracy: 0.9969 - val_loss: 0.1170 - val_accuracy: 0.9769\n",
      "Epoch 24/30\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.0078 - accuracy: 0.9975 - val_loss: 0.1305 - val_accuracy: 0.9757\n",
      "Epoch 25/30\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.1235 - val_accuracy: 0.9765\n",
      "Epoch 26/30\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.1162 - val_accuracy: 0.9798\n",
      "Epoch 27/30\n",
      "50000/50000 [==============================] - 2s 45us/step - loss: 7.5343e-04 - accuracy: 0.9999 - val_loss: 0.1154 - val_accuracy: 0.9802\n",
      "Epoch 28/30\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 3.0164e-04 - accuracy: 1.0000 - val_loss: 0.1144 - val_accuracy: 0.9803\n",
      "Epoch 29/30\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 2.3324e-04 - accuracy: 1.0000 - val_loss: 0.1156 - val_accuracy: 0.9801\n",
      "Epoch 30/30\n",
      "50000/50000 [==============================] - 2s 47us/step - loss: 1.7772e-04 - accuracy: 1.0000 - val_loss: 0.1176 - val_accuracy: 0.9803\n",
      "CPU times: user 2min 13s, sys: 8min 4s, total: 10min 18s\n",
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=30, batch_size=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Neural network hyper-parameters.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
