{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100%; !important } </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import HTML, display\n",
    "display(HTML('<style>.container { width:100%; !important } </style>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function $\\texttt{vectorized_result}(d)$ converts the digit $d \\in \\{0,\\cdots,9\\}$ and returns a NumPy vector $\\texttt{x}$ of shape $(10, 1)$ such that\n",
    "$$\n",
    "\\texttt{x}[i] = \n",
    "\\left\\{\n",
    "  \\begin{array}{ll}\n",
    "     1 & \\mbox{if $i = j$;} \\\\\n",
    "     0 & \\mbox{otherwise.}\n",
    "  \\end{array}  \n",
    "\\right.\n",
    "$$\n",
    "This function is used to convert a digit $d$ into the expected output of a neural network that has an output unit for every digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorized_result(j):\n",
    "    e = np.zeros((10, 1), dtype=np.float32)\n",
    "    e[j] = 1.0\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_result(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data that we are using is stored as a gzipped, \n",
    "<a href=\"https://docs.python.org/3/library/pickle.html\">pickled</a> file.  Therefore, we need to import the corresponding libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function $\\texttt{load_data}()$ returns a tuple of the form\n",
    "$$ (\\texttt{training_data}, \\texttt{validation_data}, \\texttt{test_data}) $$\n",
    "where \n",
    "<ul>\n",
    "<li> $\\texttt{training_data}$ is a list containing 50,000 pairs $(x, y)$ s.t.  \n",
    "     $\\textbf{x}$ is a 784-dimensional `numpy.ndarray` containing the input image and\n",
    "     $\\textbf{y}$ is a 10-dimensional `numpy.ndarray` corresponding to the correct digit for x.</li>\n",
    "<li> $\\texttt{validation_data}$ and</li>\n",
    "<li> $\\texttt{test_data}$ are lists containing 10,000 pairs $(\\textbf{x}, y)$.  In each case, \n",
    "     $\\textbf{x}$ is a 784-dimensional `numpy.ndarry` containing the input image, \n",
    "     and $y$ is the corresponding digit value.\n",
    "</ul>\n",
    "Note that the formats for training data and validation data are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    with gzip.open('mnist.pkl.gz', 'rb') as f:\n",
    "        train, validate, test = pickle.load(f, encoding=\"latin1\")\n",
    "    training_inputs   = [np.reshape(x, (784, 1)) for x in train[0]]\n",
    "    training_results  = [vectorized_result(y) for y in train[1]]\n",
    "    training_data     = zip(training_inputs, training_results)\n",
    "    validation_inputs = [np.reshape(x, (784, 1)) for x in validate[0]]\n",
    "    validation_data   = zip(validation_inputs, validate[1])\n",
    "    test_inputs       = [np.reshape(x, (784, 1)) for x in test[0]]\n",
    "    test_data         = zip(test_inputs, test[1])\n",
    "    training_data     = list(training_data)\n",
    "    validation_data   = list(validation_data)\n",
    "    test_data         = list(test_data)\n",
    "    return (training_data, validation_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We store the data in three variables `training_data`, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_data, validation_data, test_data) = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In oder to be able to view the images, we use the module `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function $\\texttt{show_digit}(\\texttt{row}, \\texttt{columns}, \\texttt{offset})$ \n",
    "shows $\\texttt{row} \\cdot \\texttt{columns}$ images of the training data.  The first image shown is the image at index $\\texttt{offset}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_digits(rows, columns, offset=0):\n",
    "    f, axarr = plt.subplots(rows, columns)\n",
    "    for r in range(rows):\n",
    "        for c in range(columns):\n",
    "            i     = r * columns + c + offset\n",
    "            image = 1 - training_data[i][0]\n",
    "            image = np.reshape(image, (28, 28))\n",
    "            axarr[r, c].imshow(image, cmap=\"gray\")\n",
    "            axarr[r, c].axis('off')\n",
    "    plt.savefig(\"digits.pdf\")    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 18 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_digits(3, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to find the weight matrices for a neural net that is able to recognize digits.  We initialize these weight matrices randomly. The function $\\texttt{rndMatrix}(\\texttt{rows}, \\texttt{cols})$ returns a matrix of shape $(\\texttt{rows}, \\texttt{cols})$ that is filled with random numbers that have a Gaussian distribution with mean $0$ and variance $\\displaystyle\\frac{1}{\\texttt{rows}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rndMatrix(rows, cols):\n",
    "    return np.random.randn(rows, cols) / np.sqrt(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.15090804,  0.69328733],\n",
       "       [-1.54436881,  0.8727093 ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rndMatrix(2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function $\\texttt{sigmoid}(x)$ computes the sigmoid of $x$, which is defined as\n",
    "$$ \\texttt{sigmoid}(x) = S(x) := \\frac{1}{1 + \\texttt{exp}(-x)}. $$ \n",
    "Since we are using NumPy to compute the exponential function, this function also works when $x$ is a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.26894142, 0.5       , 0.73105858])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(np.array([-1, 0, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function $\\texttt{sigmoid_prime}(x)$ computes the derivative of the sigmoid function for $x$.  The implementation is based on the equation:\n",
    "$$ S'(x) = S(x) \\cdot \\bigl(1 - S(x)\\bigr) $$\n",
    "$x$ can either be a number or a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_prime(x):\n",
    "    s = sigmoid(x)\n",
    "    return s * (1 - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00664806, 0.25      , 0.00664806])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid_prime(np.array([-5, 0, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class `Network` is used to represent a feedforward neural network with one hidden layer.\n",
    "The constructor is called with the argument $\\texttt{hiddenSize}$.  This parameter specifies the number of neurons in the hidden layer.  The network has $28 \\cdot 28 = 784$ input nodes.  Each of the input nodes corresponds to the gray value of a single pixel in a $28 \\cdot 28$ gray scale image of the digit that is to be recognized.  The number of output neurons is 10.  For $i \\in \\{0,\\cdots,9\\}$, the $i$th output neuron tries to recognize the digit $i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(object):\n",
    "    def __init__(self, hiddenSize):\n",
    "        self.mInputSize  = 28 * 28\n",
    "        self.mHiddenSize = hiddenSize\n",
    "        self.mOutputSize = 10\n",
    "        self.mBiasesH    = np.zeros((self.mHiddenSize, 1))   # biases hidden layer\n",
    "        self.mBiasesO    = np.zeros((self.mOutputSize, 1))   # biases output layer\n",
    "        self.mWeightsH   = rndMatrix(self.mHiddenSize, self.mInputSize)  # weights hidden layer\n",
    "        self.mWeightsO   = rndMatrix(self.mOutputSize, self.mHiddenSize) # weights output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a neural network $n$ and an input vector $x$ for this neural network, the function $n.\\texttt{feedforward}(x)$ compute the output of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedforward(self, x):\n",
    "    AH = sigmoid(self.mWeightsH @ x  + self.mBiasesH) # hidden layer\n",
    "    AO = sigmoid(self.mWeightsO @ AH + self.mBiasesO) # output layer\n",
    "    return AO\n",
    "\n",
    "Network.feedforward = feedforward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a neural network $n$, the method $\\texttt{sgd}(\\texttt{training_data}, \\texttt{epochs}, \\texttt{mbs}, \\texttt{eta}, \\texttt{test_data})$ uses stochastic gradient descent to train the network.  The parameters are as follows:\n",
    "<ul>\n",
    "<li> $\\texttt{training_data}$ is a list of tuples of the form $(x, y)$ where $x$ is an \n",
    "     input of the neural net and $y$ is a vector of length 10 representing the desired output. </li>\n",
    "<li> $\\texttt{epochs}$ is the number of epochs to train,</li>\n",
    "<li> $\\texttt{mbs}$ is the size of the minibatches,</li>\n",
    "<li> $\\texttt{eta}$ is the learning rate</li>\n",
    "<li> $\\texttt{test_data}$ is a list of tuples of the form $(x, y)$ where $x$ is an \n",
    "     input and $y$ is the desired output digit. \n",
    "</ul>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(self, training_data, epochs, mbs, eta, test_data):\n",
    "    n_test = len(test_data)\n",
    "    n      = len(training_data)\n",
    "    for j in range(epochs):\n",
    "        random.shuffle(training_data)\n",
    "        mini_batches = [training_data[k : k+mbs] for k in range(0, n, mbs)]\n",
    "        for mini_batch in mini_batches:\n",
    "            self.update_mini_batch(mini_batch, eta)    \n",
    "        print('Epoch %2d: %d / %d' % (j, self.evaluate(test_data), n_test))\n",
    "        \n",
    "Network.sgd = sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_mini_batch(self, mini_batch, eta):\n",
    "    nabla_BH = np.zeros((self.mHiddenSize, 1))  # gradient of biases  of hidden layer\n",
    "    nabla_BO = np.zeros((self.mOutputSize, 1))  # gradient of biases  of output layer\n",
    "    nabla_WH = np.zeros((self.mHiddenSize, self.mInputSize))  # gradient of weights of hidden layer\n",
    "    nabla_WO = np.zeros((self.mOutputSize, self.mHiddenSize)) # gradient of weights of output layer\n",
    "    for x, y in mini_batch:\n",
    "        dltNbl_BH, dltNbl_BO, dltNbl_WH, dltNbl_WO = self.backprop(x, y)\n",
    "        nabla_BH += dltNbl_BH\n",
    "        nabla_BO += dltNbl_BO\n",
    "        nabla_WH += dltNbl_WH\n",
    "        nabla_WO += dltNbl_WO      \n",
    "    alpha = eta / len(mini_batch)\n",
    "    self.mBiasesH  -= alpha * nabla_BH\n",
    "    self.mBiasesO  -= alpha * nabla_BO\n",
    "    self.mWeightsH -= alpha * nabla_WH\n",
    "    self.mWeightsO -= alpha * nabla_WO\n",
    "\n",
    "Network.update_mini_batch = update_mini_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a neural network $n$, the method $n.\\texttt{backprop}(x, y)$ takes a training example $(x,y)$ and calculates the gradient of the cost function with respect to this training example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop(self, x, y):\n",
    "    # feedforward pass\n",
    "    ZH = self.mWeightsH @ x  + self.mBiasesH\n",
    "    AH = sigmoid(ZH)\n",
    "    ZO = self.mWeightsO @ AH + self.mBiasesO\n",
    "    AO = sigmoid(ZO)\n",
    "    # backwards pass, output layer\n",
    "    epsilonO = (AO - y) # * sigmoid_prime(ZO)\n",
    "    nabla_BO = epsilonO\n",
    "    nabla_WO = epsilonO @ AH.transpose()\n",
    "    # backwards pass, hidden layer\n",
    "    epsilonH = (self.mWeightsO.transpose() @ epsilonO) * sigmoid_prime(ZH)\n",
    "    nabla_BH = epsilonH\n",
    "    nabla_WH = epsilonH @ x.transpose()\n",
    "    return (nabla_BH, nabla_BO, nabla_WH, nabla_WO)\n",
    "\n",
    "Network.backprop = backprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a neural network $n$, the method $n.\\texttt{evaluate}(\\texttt{test_data})$ uses the test data to compute  the number of examples that are predicted correctly by the neural network $N$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(self, test_data):\n",
    "    test_results = [(np.argmax(self.feedforward(x)), y) for (x, y) in test_data]\n",
    "    return sum(int(y1 == y2) for (y1, y2) in test_results)\n",
    "\n",
    "Network.evaluate = evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0: 9387 / 10000\n",
      "Epoch  1: 9514 / 10000\n",
      "Epoch  2: 9606 / 10000\n",
      "Epoch  3: 9643 / 10000\n",
      "Epoch  4: 9664 / 10000\n",
      "Epoch  5: 9681 / 10000\n",
      "Epoch  6: 9696 / 10000\n",
      "Epoch  7: 9691 / 10000\n",
      "Epoch  8: 9720 / 10000\n",
      "Epoch  9: 9722 / 10000\n",
      "Epoch 10: 9723 / 10000\n",
      "Epoch 11: 9724 / 10000\n",
      "Epoch 12: 9725 / 10000\n",
      "Epoch 13: 9732 / 10000\n",
      "Epoch 14: 9727 / 10000\n",
      "Epoch 15: 9734 / 10000\n",
      "Epoch 16: 9719 / 10000\n",
      "Epoch 17: 9712 / 10000\n",
      "Epoch 18: 9733 / 10000\n",
      "Epoch 19: 9740 / 10000\n",
      "Epoch 20: 9734 / 10000\n",
      "Epoch 21: 9740 / 10000\n",
      "Epoch 22: 9730 / 10000\n",
      "Epoch 23: 9738 / 10000\n",
      "Epoch 24: 9736 / 10000\n",
      "Epoch 25: 9724 / 10000\n",
      "Epoch 26: 9728 / 10000\n",
      "Epoch 27: 9737 / 10000\n",
      "Epoch 28: 9730 / 10000\n",
      "Epoch 29: 9727 / 10000\n",
      "CPU times: user 9min 19s, sys: 4.17 s, total: 9min 23s\n",
      "Wall time: 2min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "net = Network(60)\n",
    "net.sgd(training_data, 30, 20, 0.3, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
