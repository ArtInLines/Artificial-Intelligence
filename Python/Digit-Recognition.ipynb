{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100%; !important } </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import HTML, display\n",
    "display(HTML('<style>.container { width:100%; !important } </style>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "import numpy             as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function $\\texttt{vectorized_result}(d)$ converts the digit $d \\in \\{0,\\cdots,9\\}$ and returns a NumPy vector $\\mathbf{x}$ of shape $(10, 1)$ such that\n",
    "$$\n",
    "\\mathbf{x}[i] = \n",
    "\\left\\{\n",
    "  \\begin{array}{ll}\n",
    "     1 & \\mbox{if $i = d$;} \\\\\n",
    "     0 & \\mbox{otherwise.}\n",
    "  \\end{array}  \n",
    "\\right.\n",
    "$$\n",
    "This function is used to convert a digit $d$ into the expected output of a neural network that has an output unit for every digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorized_result(d):\n",
    "    e    = np.zeros((10, 1), dtype=np.float32)\n",
    "    e[d] = 1.0\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_result(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data that we are using is stored as a <a href=\"https://docs.python.org/3/library/gzip.html\">gzipped</a>, \n",
    "<a href=\"https://docs.python.org/3/library/pickle.html\">pickled</a> file.  Therefore, we need to import the corresponding libraries. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function $\\texttt{load_data}()$ returns a pair of the form\n",
    "$$ (\\texttt{training_data}, \\texttt{test_data}) $$\n",
    "where \n",
    "<ul>\n",
    "<li> $\\texttt{training_data}$ is a list containing 60,000 pairs $(\\textbf{x}, \\textbf{y})$ s.t. $\\textbf{x}$ is a 784-dimensional `numpy.ndarray` containing the input image and $\\textbf{y}$ is a 10-dimensional `numpy.ndarray` corresponding to the correct digit for x.</li>\n",
    "<li> $\\texttt{test_data}$ is a list containing 10,000 pairs $(\\textbf{x}, y)$.  In each case, \n",
    "     $\\textbf{x}$ is a 784-dimensional `numpy.ndarry` containing the input image, \n",
    "     and $y$ is the corresponding digit value.\n",
    "</ul>\n",
    "Note that the formats for training data and test data are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    with gzip.open('mnist.pkl.gz', 'rb') as f:\n",
    "        train, validate, test = pickle.load(f, encoding=\"latin1\")\n",
    "    training_inputs    = [np.reshape(x, (784, 1)) for x in train[0]]\n",
    "    training_results   = [vectorized_result(y) for y in train[1]]\n",
    "    training_data      = list(zip(training_inputs, training_results))\n",
    "    validation_inputs  = [np.reshape(x, (784, 1)) for x in validate[0]]\n",
    "    validation_results = [vectorized_result(y) for y in train[1]]\n",
    "    validation_data    = list(zip(validation_inputs, validation_results))\n",
    "    test_inputs        = [np.reshape(x, (784, 1)) for x in test[0]]\n",
    "    test_data          = list(zip(test_inputs, test[1]))\n",
    "    return (training_data + validation_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We store the data in two variables: `training_data` and `test_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_data, test_data) = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function $\\texttt{show_digit}(\\texttt{row}, \\texttt{columns}, \\texttt{offset})$ \n",
    "shows $\\texttt{row} \\cdot \\texttt{columns}$ images of the training data.  The first image shown is the image at index $\\texttt{offset}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_digits(rows, columns, offset=0):\n",
    "    f, axarr = plt.subplots(rows, columns)\n",
    "    for r in range(rows):\n",
    "        for c in range(columns):\n",
    "            i     = r * columns + c + offset\n",
    "            image = 1 - training_data[i][0]\n",
    "            image = np.reshape(image, (28, 28))\n",
    "            axarr[r, c].imshow(image, cmap=\"gray\")\n",
    "            axarr[r, c].axis('off')\n",
    "    plt.savefig(\"digits.pdf\")    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 18 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_digits(3, 6, 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to find the <em style=\"color:blue;\">weight matrices</em> and <em style=\"color:blue;\">biases</em> for a neural net that is \n",
    "able to recognize the digits shown in these images.  We initialize these weight matrices randomly. The function $\\texttt{rndMatrix}(\\texttt{rows}, \\texttt{cols})$ returns a matrix of shape $(\\texttt{rows}, \\texttt{cols})$ that is filled with random numbers that have a Gaussian distribution with mean $0$ and variance $\\displaystyle\\frac{1}{\\texttt{rows}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rndMatrix(rows, cols):\n",
    "    return np.random.randn(rows, cols) / np.sqrt(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.20723997,  0.73491183],\n",
       "       [ 0.83775179, -0.11550648]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rndMatrix(2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function $\\texttt{sigmoid}(x)$ computes the sigmoid of $x$, which is defined as\n",
    "$$ \\texttt{sigmoid}(x) = S(x) := \\frac{1}{1 + \\texttt{exp}(-x)}. $$ \n",
    "Since we are using NumPy to compute the exponential function, this function also works when $x$ is a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.26894142, 0.5       , 0.73105858])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(np.array([-1, 0, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function $\\texttt{sigmoid_prime}(x)$ computes the derivative of the sigmoid function for $x$.  The implementation is based on the equation:\n",
    "$$ S'(x) = S(x) \\cdot \\bigl(1 - S(x)\\bigr) $$\n",
    "$x$ can either be a number or a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_prime(x):\n",
    "    s = sigmoid(x)\n",
    "    return s * (1 - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00664806, 0.25      , 0.00664806])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid_prime(np.array([-5, 0, 5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class `Network` is used to represent a feedforward neural network with one hidden layer.\n",
    "The constructor is called with the argument $\\texttt{hiddenSize}$.  This parameter specifies the number of neurons in the hidden layer.  The network has $28 \\cdot 28 = 784$ input nodes.  Each of the input nodes corresponds to the gray value of a single pixel in a $28 \\cdot 28$ gray scale image of the digit that is to be recognized.  The number of output neurons is 10.  For $i \\in \\{0,\\cdots,9\\}$, the $i$th output neuron tries to recognize the digit $i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(object):\n",
    "    def __init__(self, hiddenSize):\n",
    "        self.mInputSize  = 28 * 28\n",
    "        self.mHiddenSize = hiddenSize\n",
    "        self.mOutputSize = 10\n",
    "        self.mBiasesH    = np.zeros((self.mHiddenSize, 1))   # biases hidden layer\n",
    "        self.mBiasesO    = np.zeros((self.mOutputSize, 1))   # biases output layer\n",
    "        self.mWeightsH   = rndMatrix(self.mHiddenSize, self.mInputSize)  # weights hidden layer\n",
    "        self.mWeightsO   = rndMatrix(self.mOutputSize, self.mHiddenSize) # weights output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a neural network $n$ and an input vector $x$ for this neural network, the function $n.\\texttt{feedforward}(x)$ compute the output of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedforward(self, x):\n",
    "    AH = sigmoid(self.mWeightsH @ x  + self.mBiasesH) # hidden layer\n",
    "    AO = sigmoid(self.mWeightsO @ AH + self.mBiasesO) # output layer\n",
    "    return AO\n",
    "\n",
    "Network.feedforward = feedforward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a neural network $n$, the method $\\texttt{sgd}(\\texttt{training_data}, \\texttt{epochs}, \\texttt{mbs}, \\texttt{eta}, \\texttt{test_data})$ uses stochastic gradient descent to train the network.  The parameters are as follows:\n",
    "<ul>\n",
    "<li> $\\texttt{training_data}$ is a list of tuples of the form $(x, y)$ where $x$ is an \n",
    "     input of the neural net and $y$ is a vector of length 10 representing the desired output. </li>\n",
    "<li> $\\texttt{epochs}$ is the number of epochs to train,</li>\n",
    "<li> $\\texttt{mbs}$ is the size of the minibatches,</li>\n",
    "<li> $\\texttt{eta}$ is the learning rate</li>\n",
    "<li> $\\texttt{test_data}$ is a list of tuples of the form $(x, y)$ where $x$ is an \n",
    "     input and $y$ is the desired output digit. \n",
    "</ul>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(self, training_data, epochs, mbs, eta, test_data):\n",
    "    n_test = len(test_data)\n",
    "    n      = len(training_data)\n",
    "    for j in range(epochs):\n",
    "        random.shuffle(training_data)\n",
    "        mini_batches = [training_data[k : k+mbs] for k in range(0, n, mbs)]\n",
    "        for mini_batch in mini_batches:\n",
    "            self.update_mini_batch(mini_batch, eta)    \n",
    "        print('Epoch %2d: %d / %d' % (j, self.evaluate(test_data), n_test))\n",
    "        \n",
    "Network.sgd = sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_mini_batch(self, mini_batch, eta):\n",
    "    nabla_BH = np.zeros((self.mHiddenSize, 1))  # gradient of biases  of hidden layer\n",
    "    nabla_BO = np.zeros((self.mOutputSize, 1))  # gradient of biases  of output layer\n",
    "    nabla_WH = np.zeros((self.mHiddenSize, self.mInputSize))  # gradient of weights of hidden layer\n",
    "    nabla_WO = np.zeros((self.mOutputSize, self.mHiddenSize)) # gradient of weights of output layer\n",
    "    for x, y in mini_batch:\n",
    "        dltNbl_BH, dltNbl_BO, dltNbl_WH, dltNbl_WO = self.backprop(x, y)\n",
    "        nabla_BH += dltNbl_BH\n",
    "        nabla_BO += dltNbl_BO\n",
    "        nabla_WH += dltNbl_WH\n",
    "        nabla_WO += dltNbl_WO      \n",
    "    alpha = eta / len(mini_batch)\n",
    "    self.mBiasesH  -= alpha * nabla_BH\n",
    "    self.mBiasesO  -= alpha * nabla_BO\n",
    "    self.mWeightsH -= alpha * nabla_WH\n",
    "    self.mWeightsO -= alpha * nabla_WO\n",
    "\n",
    "Network.update_mini_batch = update_mini_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a neural network $n$, the method $n.\\texttt{backprop}(x, y)$ takes a training example $(x,y)$ and calculates the gradient of the cost function with respect to this training example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop(self, x, y):\n",
    "    # feedforward pass\n",
    "    ZH = self.mWeightsH @ x  + self.mBiasesH\n",
    "    AH = sigmoid(ZH)\n",
    "    ZO = self.mWeightsO @ AH + self.mBiasesO\n",
    "    AO = sigmoid(ZO)\n",
    "    # backwards pass, output layer\n",
    "    epsilonO = (AO - y) * sigmoid_prime(ZO)\n",
    "    nabla_BO = epsilonO\n",
    "    nabla_WO = epsilonO @ AH.transpose()\n",
    "    # backwards pass, hidden layer\n",
    "    epsilonH = (self.mWeightsO.transpose() @ epsilonO) * sigmoid_prime(ZH)\n",
    "    nabla_BH = epsilonH\n",
    "    nabla_WH = epsilonH @ x.transpose()\n",
    "    return (nabla_BH, nabla_BO, nabla_WH, nabla_WO)\n",
    "\n",
    "Network.backprop = backprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a neural network $n$, the method $n.\\texttt{evaluate}(\\texttt{test_data})$ uses the test data to compute  the number of examples that are predicted correctly by the neural network $N$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(self, test_data):\n",
    "    test_results = [(np.argmax(self.feedforward(x)), y) for (x, y) in test_data]\n",
    "    return sum(y1 == y2 for (y1, y2) in test_results)\n",
    "\n",
    "Network.evaluate = evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0: 8907 / 10000\n",
      "Epoch  1: 9098 / 10000\n",
      "Epoch  2: 9148 / 10000\n",
      "Epoch  3: 9230 / 10000\n",
      "Epoch  4: 9275 / 10000\n",
      "Epoch  5: 9336 / 10000\n",
      "Epoch  6: 9361 / 10000\n",
      "Epoch  7: 9374 / 10000\n",
      "Epoch  8: 9390 / 10000\n",
      "Epoch  9: 9425 / 10000\n",
      "Epoch 10: 9436 / 10000\n",
      "Epoch 11: 9464 / 10000\n",
      "Epoch 12: 9479 / 10000\n",
      "Epoch 13: 9492 / 10000\n",
      "Epoch 14: 9507 / 10000\n",
      "Epoch 15: 9523 / 10000\n",
      "Epoch 16: 9537 / 10000\n",
      "Epoch 17: 9533 / 10000\n",
      "Epoch 18: 9541 / 10000\n",
      "Epoch 19: 9548 / 10000\n",
      "Epoch 20: 9553 / 10000\n",
      "Epoch 21: 9571 / 10000\n",
      "Epoch 22: 9574 / 10000\n",
      "Epoch 23: 9572 / 10000\n",
      "Epoch 24: 9581 / 10000\n",
      "Epoch 25: 9588 / 10000\n",
      "Epoch 26: 9592 / 10000\n",
      "Epoch 27: 9598 / 10000\n",
      "Epoch 28: 9596 / 10000\n",
      "Epoch 29: 9618 / 10000\n",
      "CPU times: user 18min 30s, sys: 2.87 s, total: 18min 33s\n",
      "Wall time: 3min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np.random.seed(1)\n",
    "net = Network(60)\n",
    "net.sgd(training_data, 30, 10, 0.1, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
