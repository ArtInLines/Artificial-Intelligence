{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%autosave 0\n",
    "from IPython.core.display import HTML, display\n",
    "display(HTML('<style>.container { width:100%; } </style>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Detection  Using a Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process of creating a spam detector using a Support Vector Machine is split up into five steps.\n",
    "\n",
    "  - Create a set of the most common words occurring in spam and ham (i.e. non-spam) emails.\n",
    "  - Transform every mail into a <em style=\"color:blue\">frequency vector</em>: For every word in the set of most common words, \n",
    "    the frequency vector stores the frequency of this word in the respective mail.\n",
    "  - For every word in the list of most common word, compute the <em style=\"color:blue\">inverse document frequency</em>.\n",
    "  - Compute the <em style=\"color:blue\">feature matrix</em> by transforming the frequency vectors into vectors that contain the product of the \n",
    "    <em style=\"color:blue\">term frequency</em> with the <em style=\"color:blue\">inverse document frequency</em>.\n",
    "  - Train and test an SVM using this <em style=\"color:blue\">feature matrix</em>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create the Set of Common Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The directory \n",
    "https://github.com/karlstroetmann/Artificial-Intelligence/tree/master/Python/EmailData\n",
    "contains 960 emails that are divided into four subdirectories:\n",
    "\n",
    "  - `spam-train` contains 350 spam emails for training,\n",
    "  - `ham-train`  contains 350 non-spam emails for training,\n",
    "  - `spam-test`  contains 130 spam emails for testing,\n",
    "  - `ham-test`   contains 130 non-spam emails for testing.\n",
    "\n",
    "I have found this data on the page \n",
    "http://openclassroom.stanford.edu/MainFolder/DocumentPage.php?course=MachineLearning&doc=exercises/ex6/ex6.html provided by Andrew Ng."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We declare some variables so that this notebook can be adapted to other data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_dir_train = 'EmailData/spam-train/'\n",
    "ham__dir_train = 'EmailData/ham-train/'\n",
    "spam_dir_test  = 'EmailData/spam-test/'\n",
    "ham__dir_test  = 'EmailData/ham-test/'\n",
    "Directories    = [spam_dir_train, ham__dir_train, spam_dir_test, ham__dir_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function $\\texttt{get_word_set}(\\texttt{fn})$ takes a filename $\\texttt{fn}$ as its argument.  It reads the file and returns a `set` of all words that are found in this file.  The words are transformed to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_set(fn):\n",
    "    with open(fn) as file:\n",
    "        text = file.read()\n",
    "        text = text.lower()\n",
    "        return set(re.findall(r\"[\\w']+\", text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `read_all_files` reads all files contained in those directories that are stored in the list `Directories`. \n",
    "It returns a `Counter`.  For every word $w$ this counter contains the number of files that contain $w$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_files():\n",
    "    Words = Counter()\n",
    "    for directory in Directories:\n",
    "        for file_name in os.listdir(directory):\n",
    "            Words.update(get_words_set(directory + file_name))\n",
    "    return Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Common_Words` is a `numpy` array of the 2500 most common words found in all of our emails. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "M            = 2500             # number of the most common words to use\n",
    "Word_Counter = read_all_files()\n",
    "Common_Words = np.array(list({ w for w, _ in Word_Counter.most_common(M) }))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Transform Files into Frequency Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Index_Dict` is a dictionary that maps from the most common words to their index in the array `Common_Words`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ph': 0,\n",
       " 'are': 1,\n",
       " 'seminar': 2,\n",
       " 'instruction': 3,\n",
       " 'figure': 4,\n",
       " 'interdisciplinary': 5,\n",
       " 'argument': 6,\n",
       " 'worldwide': 7,\n",
       " 'represent': 8,\n",
       " 'invite': 9,\n",
       " 'where': 10,\n",
       " 'discover': 11,\n",
       " 'integration': 12,\n",
       " 'page': 13,\n",
       " 'server': 14,\n",
       " 'saturday': 15,\n",
       " 'jackson': 16,\n",
       " 'encode': 17,\n",
       " 'paid': 18,\n",
       " 'acceptance': 19,\n",
       " 'europe': 20,\n",
       " 'global': 21,\n",
       " 'pic': 22,\n",
       " 'bibliography': 23,\n",
       " 'wealthy': 24,\n",
       " 'classified': 25,\n",
       " 'merge': 26,\n",
       " 'removal': 27,\n",
       " 'lower': 28,\n",
       " 'overt': 29,\n",
       " 'fellow': 30,\n",
       " 'loui': 31,\n",
       " 'author': 32,\n",
       " 'install': 33,\n",
       " 'fairchild': 34,\n",
       " 'competitor': 35,\n",
       " 'fresh': 36,\n",
       " 'hardcore': 37,\n",
       " 'christmas': 38,\n",
       " 'satisfaction': 39,\n",
       " 'below': 40,\n",
       " 'away': 41,\n",
       " 'file': 42,\n",
       " 'information': 43,\n",
       " 'management': 44,\n",
       " 'importance': 45,\n",
       " 'counter': 46,\n",
       " 'alan': 47,\n",
       " 'congress': 48,\n",
       " 'telephone': 49,\n",
       " 'frequently': 50,\n",
       " 'locate': 51,\n",
       " 'mistake': 52,\n",
       " 'short': 53,\n",
       " 'overview': 54,\n",
       " 'create': 55,\n",
       " 'sometime': 56,\n",
       " 'teach': 57,\n",
       " 'answer': 58,\n",
       " 'accepted': 59,\n",
       " 'theoretical': 60,\n",
       " 'procedure': 61,\n",
       " 'stuff': 62,\n",
       " 'radio': 63,\n",
       " 'intend': 64,\n",
       " 'glad': 65,\n",
       " 'instructions': 66,\n",
       " 'lead': 67,\n",
       " 'illegal': 68,\n",
       " 'corpus': 69,\n",
       " 'surface': 70,\n",
       " 'rat': 71,\n",
       " 'postscript': 72,\n",
       " 'unique': 73,\n",
       " 'casino': 74,\n",
       " 'merely': 75,\n",
       " 'while': 76,\n",
       " 'devote': 77,\n",
       " 'merciless': 78,\n",
       " 'fulfill': 79,\n",
       " 'st': 80,\n",
       " 'persistent': 81,\n",
       " 'product': 82,\n",
       " 'proposal': 83,\n",
       " 'grammatical': 84,\n",
       " 'harvard': 85,\n",
       " 'programme': 86,\n",
       " 'profitable': 87,\n",
       " 'regards': 88,\n",
       " 'extract': 89,\n",
       " 'illustrate': 90,\n",
       " 'summarize': 91,\n",
       " 'click': 92,\n",
       " 'doe': 93,\n",
       " 'miss': 94,\n",
       " 'local': 95,\n",
       " 'ease': 96,\n",
       " 'relevance': 97,\n",
       " 'observe': 98,\n",
       " 'black': 99,\n",
       " 'morpheme': 100,\n",
       " 'phonological': 101,\n",
       " 'replace': 102,\n",
       " 'synthesis': 103,\n",
       " 'variation': 104,\n",
       " 'enough': 105,\n",
       " 'power': 106,\n",
       " 'philadelphium': 107,\n",
       " 'own': 108,\n",
       " 'oversea': 109,\n",
       " 'chat': 110,\n",
       " 'consequence': 111,\n",
       " 'stable': 112,\n",
       " 'discipline': 113,\n",
       " 'seek': 114,\n",
       " 'cum': 115,\n",
       " 'thus': 116,\n",
       " 'one': 117,\n",
       " 'turn': 118,\n",
       " 'permanently': 119,\n",
       " 'basis': 120,\n",
       " 'gather': 121,\n",
       " 'rejection': 122,\n",
       " 'factor': 123,\n",
       " 'itself': 124,\n",
       " 'parameter': 125,\n",
       " 'max': 126,\n",
       " 'usually': 127,\n",
       " 'host': 128,\n",
       " 'anonymous': 129,\n",
       " 'clean': 130,\n",
       " 'unmark': 131,\n",
       " 'commercial': 132,\n",
       " 'quit': 133,\n",
       " 'education': 134,\n",
       " 'george': 135,\n",
       " 'bear': 136,\n",
       " 'secretary': 137,\n",
       " 'device': 138,\n",
       " 'vary': 139,\n",
       " 'listing': 140,\n",
       " 'active': 141,\n",
       " 'advance': 142,\n",
       " 'summer': 143,\n",
       " 'greater': 144,\n",
       " 'universite': 145,\n",
       " 'musical': 146,\n",
       " 'net': 147,\n",
       " 'traditional': 148,\n",
       " 'symposium': 149,\n",
       " 'meet': 150,\n",
       " 'ourselve': 151,\n",
       " 'keep': 152,\n",
       " 'similar': 153,\n",
       " 'recipient': 154,\n",
       " 'reader': 155,\n",
       " 'tag': 156,\n",
       " 'attach': 157,\n",
       " 'visit': 158,\n",
       " 'field': 159,\n",
       " 'florida': 160,\n",
       " 'fee': 161,\n",
       " 'adults': 162,\n",
       " 'grow': 163,\n",
       " 'hundr': 164,\n",
       " 'snail': 165,\n",
       " 'accomplish': 166,\n",
       " 'hard': 167,\n",
       " 'character': 168,\n",
       " 'engineer': 169,\n",
       " 'realistic': 170,\n",
       " 'white': 171,\n",
       " 'fastest': 172,\n",
       " 'michigan': 173,\n",
       " 'resident': 174,\n",
       " 'karen': 175,\n",
       " 'nl': 176,\n",
       " 'mix': 177,\n",
       " 'prefer': 178,\n",
       " 'fortune': 179,\n",
       " 'fail': 180,\n",
       " 'card': 181,\n",
       " 'most': 182,\n",
       " 'contrast': 183,\n",
       " 'age': 184,\n",
       " 'extraordinary': 185,\n",
       " 'imply': 186,\n",
       " 'prospective': 187,\n",
       " 'don': 188,\n",
       " 'serve': 189,\n",
       " 'load': 190,\n",
       " 'build': 191,\n",
       " 'sequence': 192,\n",
       " 'smith': 193,\n",
       " 'der': 194,\n",
       " 'perception': 195,\n",
       " 'every': 196,\n",
       " 'christian': 197,\n",
       " 'put': 198,\n",
       " 'thanks': 199,\n",
       " 'sprachwissenschaft': 200,\n",
       " 'thompson': 201,\n",
       " 'privacy': 202,\n",
       " 'want': 203,\n",
       " 'major': 204,\n",
       " 'control': 205,\n",
       " 'link': 206,\n",
       " 'choice': 207,\n",
       " 'diachronic': 208,\n",
       " 'waste': 209,\n",
       " 'dream': 210,\n",
       " 'principle': 211,\n",
       " 'promise': 212,\n",
       " 'spend': 213,\n",
       " 'wonderful': 214,\n",
       " 'tense': 215,\n",
       " 'awhile': 216,\n",
       " 'cultural': 217,\n",
       " 'back': 218,\n",
       " 'variety': 219,\n",
       " 'million': 220,\n",
       " 'award': 221,\n",
       " 'patent': 222,\n",
       " 'additional': 223,\n",
       " 'literature': 224,\n",
       " 'advertise': 225,\n",
       " 'quality': 226,\n",
       " 'something': 227,\n",
       " 'practice': 228,\n",
       " 'steve': 229,\n",
       " 'die': 230,\n",
       " 'pm': 231,\n",
       " 'minimum': 232,\n",
       " 'truly': 233,\n",
       " 'structure': 234,\n",
       " 'relation': 235,\n",
       " 'surely': 236,\n",
       " 'journal': 237,\n",
       " 'sameday': 238,\n",
       " 'amount': 239,\n",
       " 'hand': 240,\n",
       " 'ordering': 241,\n",
       " 'outstand': 242,\n",
       " 'cameraready': 243,\n",
       " 'too': 244,\n",
       " 'former': 245,\n",
       " 'technique': 246,\n",
       " 'industrial': 247,\n",
       " 'gamble': 248,\n",
       " 'appeal': 249,\n",
       " 'week': 250,\n",
       " 'context': 251,\n",
       " 'order': 252,\n",
       " 'reveal': 253,\n",
       " 'step': 254,\n",
       " 'thousand': 255,\n",
       " 'psychology': 256,\n",
       " 'sheffield': 257,\n",
       " 'boyfriend': 258,\n",
       " 'inquiry': 259,\n",
       " 'credit': 260,\n",
       " 'cash': 261,\n",
       " 'extraction': 262,\n",
       " 'educational': 263,\n",
       " 'previous': 264,\n",
       " 'prosodic': 265,\n",
       " 'organiser': 266,\n",
       " 'ready': 267,\n",
       " 'mode': 268,\n",
       " 'off': 269,\n",
       " 'pragmatic': 270,\n",
       " 'cognition': 271,\n",
       " 'referral': 272,\n",
       " 'vium': 273,\n",
       " 'eric': 274,\n",
       " 'attack': 275,\n",
       " 'staff': 276,\n",
       " 'computational': 277,\n",
       " 'monitor': 278,\n",
       " 'skill': 279,\n",
       " 'email': 280,\n",
       " 'central': 281,\n",
       " 'patrick': 282,\n",
       " 'material': 283,\n",
       " 'plan': 284,\n",
       " 'morphology': 285,\n",
       " 'store': 286,\n",
       " 'space': 287,\n",
       " 'purpose': 288,\n",
       " 'publicity': 289,\n",
       " 'talk': 290,\n",
       " 'print': 291,\n",
       " 'emailer': 292,\n",
       " 'summary': 293,\n",
       " 'actual': 294,\n",
       " 'inch': 295,\n",
       " 'imagination': 296,\n",
       " 'must': 297,\n",
       " 'difficult': 298,\n",
       " 'sample': 299,\n",
       " 'win': 300,\n",
       " 'salary': 301,\n",
       " 'header': 302,\n",
       " 'diversity': 303,\n",
       " 'acquire': 304,\n",
       " 'latter': 305,\n",
       " 'seriously': 306,\n",
       " 'amazing': 307,\n",
       " 'close': 308,\n",
       " 'serious': 309,\n",
       " 'optional': 310,\n",
       " 'organizer': 311,\n",
       " 'low': 312,\n",
       " 'collect': 313,\n",
       " 'introductory': 314,\n",
       " 'realize': 315,\n",
       " 'conversational': 316,\n",
       " 'line': 317,\n",
       " 'works': 318,\n",
       " 'play': 319,\n",
       " 'august': 320,\n",
       " 'teacher': 321,\n",
       " 'classic': 322,\n",
       " 'video': 323,\n",
       " 'd': 324,\n",
       " 'agreement': 325,\n",
       " 'paradise': 326,\n",
       " 'joseph': 327,\n",
       " 'france': 328,\n",
       " 'biz': 329,\n",
       " 'standard': 330,\n",
       " 'sum': 331,\n",
       " 'accurately': 332,\n",
       " 'semantics': 333,\n",
       " 'express': 334,\n",
       " 'scheme': 335,\n",
       " 'organisation': 336,\n",
       " 'under': 337,\n",
       " 'mit': 338,\n",
       " 'postal': 339,\n",
       " 'demo': 340,\n",
       " 'publication': 341,\n",
       " 'tax': 342,\n",
       " 'verbal': 343,\n",
       " 'love': 344,\n",
       " 'southern': 345,\n",
       " 'archive': 346,\n",
       " 'believer': 347,\n",
       " 'promotion': 348,\n",
       " 'compile': 349,\n",
       " 'th': 350,\n",
       " 'recognition': 351,\n",
       " 'example': 352,\n",
       " 'act': 353,\n",
       " 'program': 354,\n",
       " 'association': 355,\n",
       " 'prepare': 356,\n",
       " 'upgrade': 357,\n",
       " 'friendly': 358,\n",
       " 'free': 359,\n",
       " 'oh': 360,\n",
       " 'tom': 361,\n",
       " 'letter': 362,\n",
       " 'blackwell': 363,\n",
       " 'issue': 364,\n",
       " 'june': 365,\n",
       " 'oral': 366,\n",
       " 'vendor': 367,\n",
       " 'thank': 368,\n",
       " 'accountant': 369,\n",
       " 'average': 370,\n",
       " 'asian': 371,\n",
       " 'february': 372,\n",
       " 'code': 373,\n",
       " 'editorial': 374,\n",
       " 'lay': 375,\n",
       " 'update': 376,\n",
       " 'cost': 377,\n",
       " 'filter': 378,\n",
       " 'marketing': 379,\n",
       " 'preview': 380,\n",
       " 'section': 381,\n",
       " 'better': 382,\n",
       " 'register': 383,\n",
       " 'rockland': 384,\n",
       " 'throughout': 385,\n",
       " 'promote': 386,\n",
       " 'begin': 387,\n",
       " 'unlike': 388,\n",
       " 'lifetime': 389,\n",
       " 'nominal': 390,\n",
       " 'dutch': 391,\n",
       " 'proper': 392,\n",
       " 'planet': 393,\n",
       " 'alternative': 394,\n",
       " 'coverage': 395,\n",
       " 'class': 396,\n",
       " 'santa': 397,\n",
       " 'two': 398,\n",
       " 'alway': 399,\n",
       " 'listen': 400,\n",
       " 'beautiful': 401,\n",
       " 'remember': 402,\n",
       " 'federal': 403,\n",
       " 'awesome': 404,\n",
       " 'generate': 405,\n",
       " 'operate': 406,\n",
       " 'feature': 407,\n",
       " 'guarantee': 408,\n",
       " 'effort': 409,\n",
       " 'possible': 410,\n",
       " 'cannot': 411,\n",
       " 'alone': 412,\n",
       " 'category': 413,\n",
       " 'security': 414,\n",
       " 'stock': 415,\n",
       " 'whole': 416,\n",
       " 'positive': 417,\n",
       " 'microsoft': 418,\n",
       " 'anne': 419,\n",
       " 'insert': 420,\n",
       " 'avoid': 421,\n",
       " 'analyze': 422,\n",
       " 'days': 423,\n",
       " 'particular': 424,\n",
       " 'draft': 425,\n",
       " 'husband': 426,\n",
       " 'successful': 427,\n",
       " 'broad': 428,\n",
       " 'jump': 429,\n",
       " 'extension': 430,\n",
       " 'reach': 431,\n",
       " 'creditor': 432,\n",
       " 'goods': 433,\n",
       " 'internal': 434,\n",
       " 'finance': 435,\n",
       " 'king': 436,\n",
       " 'toward': 437,\n",
       " 'clause': 438,\n",
       " 'jone': 439,\n",
       " 'plus': 440,\n",
       " 'az': 441,\n",
       " 'gold': 442,\n",
       " 'selection': 443,\n",
       " 'reply': 444,\n",
       " 'relative': 445,\n",
       " 'accompany': 446,\n",
       " 'electronically': 447,\n",
       " 'choose': 448,\n",
       " 'require': 449,\n",
       " 'theme': 450,\n",
       " 'root': 451,\n",
       " 'person': 452,\n",
       " 'without': 453,\n",
       " 'first': 454,\n",
       " 'distribute': 455,\n",
       " 'bet': 456,\n",
       " 'yield': 457,\n",
       " 'cent': 458,\n",
       " 'paste': 459,\n",
       " 'solution': 460,\n",
       " 'move': 461,\n",
       " 'spout': 462,\n",
       " 'msn': 463,\n",
       " 'assessment': 464,\n",
       " 'genuine': 465,\n",
       " 'andrew': 466,\n",
       " 'multus': 467,\n",
       " 'subscription': 468,\n",
       " 'generative': 469,\n",
       " 'front': 470,\n",
       " 'correctly': 471,\n",
       " 'evaluate': 472,\n",
       " 'paragraph': 473,\n",
       " 'rate': 474,\n",
       " 'director': 475,\n",
       " 'early': 476,\n",
       " 'seem': 477,\n",
       " 'homepage': 478,\n",
       " 'retail': 479,\n",
       " 'difficulty': 480,\n",
       " 'translation': 481,\n",
       " 'everythe': 482,\n",
       " 'performance': 483,\n",
       " 'cancel': 484,\n",
       " 'amex': 485,\n",
       " 'read': 486,\n",
       " 'massachusett': 487,\n",
       " 'customer': 488,\n",
       " 'speak': 489,\n",
       " 'wolfgang': 490,\n",
       " 'appear': 491,\n",
       " 'however': 492,\n",
       " 'suppose': 493,\n",
       " 'general': 494,\n",
       " 'fine': 495,\n",
       " 'separate': 496,\n",
       " 'exactly': 497,\n",
       " 'therefore': 498,\n",
       " 'suggestion': 499,\n",
       " 'judgment': 500,\n",
       " 'disk': 501,\n",
       " 'granada': 502,\n",
       " 'weekly': 503,\n",
       " 'typical': 504,\n",
       " 'ann': 505,\n",
       " 'english': 506,\n",
       " 'valuable': 507,\n",
       " 'party': 508,\n",
       " 'isbn': 509,\n",
       " 'intention': 510,\n",
       " 'derive': 511,\n",
       " 'financial': 512,\n",
       " 'contact': 513,\n",
       " 'us': 514,\n",
       " 'call': 515,\n",
       " 'ca': 516,\n",
       " 'floor': 517,\n",
       " 'effectively': 518,\n",
       " 'become': 519,\n",
       " 'surprise': 520,\n",
       " 'anthropology': 521,\n",
       " 'emerge': 522,\n",
       " 'e': 523,\n",
       " 'minority': 524,\n",
       " 'capital': 525,\n",
       " 'enhance': 526,\n",
       " 'themselve': 527,\n",
       " 'shall': 528,\n",
       " 'end': 529,\n",
       " 'highway': 530,\n",
       " 'ii': 531,\n",
       " 'brief': 532,\n",
       " 'economy': 533,\n",
       " 'workshop': 534,\n",
       " 'edinburgh': 535,\n",
       " 'tend': 536,\n",
       " 'photo': 537,\n",
       " 'thoma': 538,\n",
       " 'martinez': 539,\n",
       " 'retrieval': 540,\n",
       " 'focus': 541,\n",
       " 'patient': 542,\n",
       " 'colleague': 543,\n",
       " 'again': 544,\n",
       " 'joan': 545,\n",
       " 'larger': 546,\n",
       " 'citation': 547,\n",
       " 'minimal': 548,\n",
       " 'porn': 549,\n",
       " 'sit': 550,\n",
       " 'optimality': 551,\n",
       " 'confidence': 552,\n",
       " 'operator': 553,\n",
       " 'limit': 554,\n",
       " 'least': 555,\n",
       " 'obligation': 556,\n",
       " 'criminal': 557,\n",
       " 'compute': 558,\n",
       " 'television': 559,\n",
       " 'reserve': 560,\n",
       " 'reports': 561,\n",
       " 'org': 562,\n",
       " 'owe': 563,\n",
       " 'watch': 564,\n",
       " 'promotional': 565,\n",
       " 'region': 566,\n",
       " 'cover': 567,\n",
       " 'newspaper': 568,\n",
       " 'female': 569,\n",
       " 'lexical': 570,\n",
       " 'format': 571,\n",
       " 'wish': 572,\n",
       " 'morn': 573,\n",
       " 'detail': 574,\n",
       " 'personality': 575,\n",
       " 'completely': 576,\n",
       " 'pb': 577,\n",
       " 'sent': 578,\n",
       " 'illinoi': 579,\n",
       " 'ever': 580,\n",
       " 'overload': 581,\n",
       " 'f': 582,\n",
       " 'school': 583,\n",
       " 'place': 584,\n",
       " 'buyer': 585,\n",
       " 've': 586,\n",
       " 'hit': 587,\n",
       " 'ma': 588,\n",
       " 'assist': 589,\n",
       " 'lack': 590,\n",
       " 'legal': 591,\n",
       " 'strip': 592,\n",
       " 'live': 593,\n",
       " 'warn': 594,\n",
       " 'ongo': 595,\n",
       " 'statistics': 596,\n",
       " 'colingacl': 597,\n",
       " 'science': 598,\n",
       " 'bill': 599,\n",
       " 'universal': 600,\n",
       " 'against': 601,\n",
       " 'image': 602,\n",
       " 'yet': 603,\n",
       " 'pittsburgh': 604,\n",
       " 'differently': 605,\n",
       " 'top': 606,\n",
       " 'billion': 607,\n",
       " 'especially': 608,\n",
       " 'richard': 609,\n",
       " 'soon': 610,\n",
       " 'secrets': 611,\n",
       " 'contribute': 612,\n",
       " 'fantastic': 613,\n",
       " 'selle': 614,\n",
       " 'money': 615,\n",
       " 'success': 616,\n",
       " 'royal': 617,\n",
       " 'path': 618,\n",
       " 'response': 619,\n",
       " 'nd': 620,\n",
       " 'syllable': 621,\n",
       " 'work': 622,\n",
       " 'entirely': 623,\n",
       " 'base': 624,\n",
       " 'tape': 625,\n",
       " 'budget': 626,\n",
       " 'participate': 627,\n",
       " 'junk': 628,\n",
       " 'history': 629,\n",
       " 'gov': 630,\n",
       " 'late': 631,\n",
       " 'gb': 632,\n",
       " 'try': 633,\n",
       " 'consider': 634,\n",
       " 'survey': 635,\n",
       " 'recieve': 636,\n",
       " 'worker': 637,\n",
       " 'convince': 638,\n",
       " 'rank': 639,\n",
       " 'second': 640,\n",
       " 'side': 641,\n",
       " 'und': 642,\n",
       " 'longer': 643,\n",
       " 'bargain': 644,\n",
       " 'israel': 645,\n",
       " 'busy': 646,\n",
       " 'movement': 647,\n",
       " 'johanna': 648,\n",
       " 'earth': 649,\n",
       " 'spanish': 650,\n",
       " 'copy': 651,\n",
       " 'contract': 652,\n",
       " 'lose': 653,\n",
       " 'romance': 654,\n",
       " 'batch': 655,\n",
       " 'skeptical': 656,\n",
       " 'five': 657,\n",
       " 'degree': 658,\n",
       " 'registration': 659,\n",
       " 'orders': 660,\n",
       " 'conversation': 661,\n",
       " 'lee': 662,\n",
       " 'chance': 663,\n",
       " 'phrase': 664,\n",
       " 'guideline': 665,\n",
       " 'excellent': 666,\n",
       " 'bid': 667,\n",
       " 'pari': 668,\n",
       " 'charge': 669,\n",
       " 'copyright': 670,\n",
       " 'advantage': 671,\n",
       " 'cleanest': 672,\n",
       " 'map': 673,\n",
       " 'native': 674,\n",
       " 'netherland': 675,\n",
       " 'report': 676,\n",
       " 'fill': 677,\n",
       " 'circle': 678,\n",
       " 'recognize': 679,\n",
       " 'resell': 680,\n",
       " 'start': 681,\n",
       " 'night': 682,\n",
       " 'employment': 683,\n",
       " 'series': 684,\n",
       " 'italy': 685,\n",
       " 'deposit': 686,\n",
       " 'martin': 687,\n",
       " 'county': 688,\n",
       " 'count': 689,\n",
       " 'comprehensive': 690,\n",
       " 'le': 691,\n",
       " 'speakers': 692,\n",
       " 'speaker': 693,\n",
       " 'delivery': 694,\n",
       " 'share': 695,\n",
       " 'either': 696,\n",
       " 'van': 697,\n",
       " 'note': 698,\n",
       " 'phonology': 699,\n",
       " 's': 700,\n",
       " 'clearly': 701,\n",
       " 'conjunction': 702,\n",
       " 'indefinite': 703,\n",
       " 'over': 704,\n",
       " 'priority': 705,\n",
       " 'direct': 706,\n",
       " 'somewhat': 707,\n",
       " 'agree': 708,\n",
       " 'moreover': 709,\n",
       " 'directly': 710,\n",
       " 'david': 711,\n",
       " 'review': 712,\n",
       " 'york': 713,\n",
       " 'zip': 714,\n",
       " 'susan': 715,\n",
       " 'hundreds': 716,\n",
       " 'plenary': 717,\n",
       " 'totals': 718,\n",
       " 'll': 719,\n",
       " 'nancy': 720,\n",
       " 'highlight': 721,\n",
       " 'newest': 722,\n",
       " 'driver': 723,\n",
       " 'typology': 724,\n",
       " 'cycle': 725,\n",
       " 'our': 726,\n",
       " 'tradition': 727,\n",
       " 'services': 728,\n",
       " 'spouse': 729,\n",
       " 'capability': 730,\n",
       " 'extent': 731,\n",
       " 're': 732,\n",
       " 'removed': 733,\n",
       " 'able': 734,\n",
       " 'faster': 735,\n",
       " 'reg': 736,\n",
       " 'insurance': 737,\n",
       " 'evergrow': 738,\n",
       " 'upon': 739,\n",
       " 'already': 740,\n",
       " 'id': 741,\n",
       " 'expense': 742,\n",
       " 'q': 743,\n",
       " 'texa': 744,\n",
       " 'firm': 745,\n",
       " 'hobby': 746,\n",
       " 'tip': 747,\n",
       " 'connection': 748,\n",
       " 'release': 749,\n",
       " 'web': 750,\n",
       " 'assume': 751,\n",
       " 'webmaster': 752,\n",
       " 'maria': 753,\n",
       " 'addition': 754,\n",
       " 'combine': 755,\n",
       " 'rutger': 756,\n",
       " 'worth': 757,\n",
       " 'se': 758,\n",
       " 'receipt': 759,\n",
       " 'color': 760,\n",
       " 'meg': 761,\n",
       " 'winner': 762,\n",
       " 'identity': 763,\n",
       " 'nlg': 764,\n",
       " 'site': 765,\n",
       " 'responsibility': 766,\n",
       " 'stun': 767,\n",
       " 'hardware': 768,\n",
       " 'introduce': 769,\n",
       " 'american': 770,\n",
       " 'tuesday': 771,\n",
       " 'criterion': 772,\n",
       " 'schedule': 773,\n",
       " 'understand': 774,\n",
       " 'cognitive': 775,\n",
       " 'stamp': 776,\n",
       " 'whom': 777,\n",
       " 'michael': 778,\n",
       " 'au': 779,\n",
       " 'refinance': 780,\n",
       " 'instance': 781,\n",
       " 'phenomenon': 782,\n",
       " 'agent': 783,\n",
       " 'helpful': 784,\n",
       " 'big': 785,\n",
       " 'nor': 786,\n",
       " 'ny': 787,\n",
       " 'evolution': 788,\n",
       " 'k': 789,\n",
       " 'temporal': 790,\n",
       " 'inc': 791,\n",
       " 'comparative': 792,\n",
       " 'classroom': 793,\n",
       " 'part': 794,\n",
       " 'deep': 795,\n",
       " 'bernadette': 796,\n",
       " 'raleigh': 797,\n",
       " 'surround': 798,\n",
       " 'robert': 799,\n",
       " 'word': 800,\n",
       " 'concern': 801,\n",
       " 'mention': 802,\n",
       " 'reviewer': 803,\n",
       " 'frank': 804,\n",
       " 'debt': 805,\n",
       " 'log': 806,\n",
       " 'johnson': 807,\n",
       " 'concept': 808,\n",
       " 'fit': 809,\n",
       " 'pa': 810,\n",
       " 'il': 811,\n",
       " 'remark': 812,\n",
       " 'al': 813,\n",
       " 'manchester': 814,\n",
       " 'psychological': 815,\n",
       " 'walk': 816,\n",
       " 'rock': 817,\n",
       " 'deal': 818,\n",
       " 'rather': 819,\n",
       " 'explanation': 820,\n",
       " 'legitimate': 821,\n",
       " 'san': 822,\n",
       " 'study': 823,\n",
       " 'forum': 824,\n",
       " 'entitle': 825,\n",
       " 'confident': 826,\n",
       " 'monthly': 827,\n",
       " 'october': 828,\n",
       " 'exact': 829,\n",
       " 'lang': 830,\n",
       " 'between': 831,\n",
       " 'nt': 832,\n",
       " 'anna': 833,\n",
       " 'personal': 834,\n",
       " 'pl': 835,\n",
       " 'nation': 836,\n",
       " 'grand': 837,\n",
       " 'achievement': 838,\n",
       " 'living': 839,\n",
       " 'cause': 840,\n",
       " 'goal': 841,\n",
       " 'quite': 842,\n",
       " 'expensive': 843,\n",
       " 'mastercard': 844,\n",
       " 'polish': 845,\n",
       " 'operation': 846,\n",
       " 'those': 847,\n",
       " 'corner': 848,\n",
       " 'decide': 849,\n",
       " 'http': 850,\n",
       " 'has': 851,\n",
       " 'fall': 852,\n",
       " 'organise': 853,\n",
       " 'location': 854,\n",
       " 'abstract': 855,\n",
       " 'profit': 856,\n",
       " 'higher': 857,\n",
       " 'parse': 858,\n",
       " 'why': 859,\n",
       " 'neither': 860,\n",
       " 'abstracts': 861,\n",
       " 'handbook': 862,\n",
       " 'spokane': 863,\n",
       " 'quantifier': 864,\n",
       " 'naturally': 865,\n",
       " 'bonus': 866,\n",
       " 'race': 867,\n",
       " 'contents': 868,\n",
       " 'lo': 869,\n",
       " 'center': 870,\n",
       " 'channel': 871,\n",
       " 'cyber': 872,\n",
       " 'quebec': 873,\n",
       " 'client': 874,\n",
       " 'subject': 875,\n",
       " 'let': 876,\n",
       " 'import': 877,\n",
       " 'lawyer': 878,\n",
       " 'project': 879,\n",
       " 'definitely': 880,\n",
       " 'dial': 881,\n",
       " 'range': 882,\n",
       " 'unify': 883,\n",
       " 'question': 884,\n",
       " 'trial': 885,\n",
       " 'mailer': 886,\n",
       " 'real': 887,\n",
       " 'incredible': 888,\n",
       " 'upto': 889,\n",
       " 'complexity': 890,\n",
       " 'correspond': 891,\n",
       " 'isp': 892,\n",
       " 'undergraduate': 893,\n",
       " 'likely': 894,\n",
       " 'area': 895,\n",
       " 'twelve': 896,\n",
       " 'automatic': 897,\n",
       " 'absolutely': 898,\n",
       " 'logical': 899,\n",
       " 'independence': 900,\n",
       " 'post': 901,\n",
       " 'y': 902,\n",
       " 'marketer': 903,\n",
       " 'universitaet': 904,\n",
       " 'solid': 905,\n",
       " 'comment': 906,\n",
       " 'weight': 907,\n",
       " 'thereafter': 908,\n",
       " 'german': 909,\n",
       " 'intelligent': 910,\n",
       " 'participant': 911,\n",
       " 'light': 912,\n",
       " 'interpretation': 913,\n",
       " 'reprint': 914,\n",
       " 'january': 915,\n",
       " 'invest': 916,\n",
       " 'statistical': 917,\n",
       " 'sentence': 918,\n",
       " 'panel': 919,\n",
       " 'j': 920,\n",
       " 'constantly': 921,\n",
       " 'discussion': 922,\n",
       " 'possibly': 923,\n",
       " 'venue': 924,\n",
       " 'april': 925,\n",
       " 'envelope': 926,\n",
       " 'signal': 927,\n",
       " 'handle': 928,\n",
       " 'goe': 929,\n",
       " 'innovative': 930,\n",
       " 'logic': 931,\n",
       " 'ext': 932,\n",
       " 'largest': 933,\n",
       " 'accessible': 934,\n",
       " 'making': 935,\n",
       " 'significant': 936,\n",
       " 'audience': 937,\n",
       " 'outside': 938,\n",
       " 'currency': 939,\n",
       " 'generation': 940,\n",
       " 'oxford': 941,\n",
       " 'unite': 942,\n",
       " 'anon': 943,\n",
       " 'fl': 944,\n",
       " 'roll': 945,\n",
       " 'analyse': 946,\n",
       " 'currently': 947,\n",
       " 'ltd': 948,\n",
       " 'buck': 949,\n",
       " 'classify': 950,\n",
       " 'cheap': 951,\n",
       " 'quick': 952,\n",
       " 'communicate': 953,\n",
       " 'numbers': 954,\n",
       " 'advise': 955,\n",
       " 'western': 956,\n",
       " 'day': 957,\n",
       " 'pc': 958,\n",
       " 'country': 959,\n",
       " 'excess': 960,\n",
       " 'favorite': 961,\n",
       " 'whatsoever': 962,\n",
       " 'doctor': 963,\n",
       " 'astonishment': 964,\n",
       " 'co': 965,\n",
       " 'convenience': 966,\n",
       " 'phonetics': 967,\n",
       " 'compete': 968,\n",
       " 'lottery': 969,\n",
       " 'zero': 970,\n",
       " 'brand': 971,\n",
       " 'syntax': 972,\n",
       " 'system': 973,\n",
       " 'desirable': 974,\n",
       " 'particularly': 975,\n",
       " 'commonly': 976,\n",
       " 'cm': 977,\n",
       " 'solve': 978,\n",
       " 'weekend': 979,\n",
       " 'expand': 980,\n",
       " 'same': 981,\n",
       " 'application': 982,\n",
       " 'comparison': 983,\n",
       " 'edit': 984,\n",
       " 'doubt': 985,\n",
       " 'population': 986,\n",
       " 'relevant': 987,\n",
       " 'view': 988,\n",
       " 'puzzle': 989,\n",
       " 'possibility': 990,\n",
       " 'owner': 991,\n",
       " 'pacific': 992,\n",
       " 'dollars': 993,\n",
       " 'suit': 994,\n",
       " 'food': 995,\n",
       " 'literary': 996,\n",
       " 'continent': 997,\n",
       " 'duplicate': 998,\n",
       " 'press': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Index_Dict = { w: i for i, w in enumerate(Common_Words) }\n",
    "Index_Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function $\\texttt{transform_to_vector}(L)$ takes a list of words $L$ and transforms this list into a vector $\\mathbf{v}$.  If \n",
    "$\\texttt{CommonWords}[i] = w$, then $\\mathbf{v}[i]$ specifies the number of times that $w$ occurs in $L$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_vector(L):\n",
    "    Result = np.zeros((len(Common_Words, )))\n",
    "    for w in L:\n",
    "        if w in Index_Dict:\n",
    "            Result[Index_Dict[w]] += 1\n",
    "    return Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function $\\texttt{get_word_vector}(fn)$ takes a filename `fn`, reads the specified file and transforms it into a feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_vector(fn):\n",
    "    with open(fn) as file:\n",
    "        text = file.read()\n",
    "        text = text.lower()\n",
    "        return transform_to_vector(re.findall(r\"[\\w']+\", text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Compute the Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In natural language processing, the notion <em style='color:blue;'>term</em> is used as a synonym for <em style='color:blue;'>word</em>.\n",
    "Given a term $t$ and a document $d$, the <em style='color:blue;'>term frequency</em> $\\texttt{tf}(t, d)$ is defined as\n",
    "$$ \\texttt{tf}(t, d) = \\frac{d.\\texttt{count}(t)}{\\texttt{len}(d)}, $$\n",
    "where $d.\\texttt{count}(t)$ counts the number of times $t$ appears in $d$ and $\\texttt{len}(d)$ is the length of the list representing $d$.\n",
    "\n",
    "A <em style='color:blue;'>corpus</em> is a set of documents.  Given a term $t$ and a corpus $\\mathcal{C}$, the <em style='color:blue;'>inverse document frequency</em> \n",
    "$\\texttt{idf}(t,\\mathcal{C})$ is defined as\n",
    "$$ \\texttt{idf}(t,\\mathcal{C}) = \\ln\\left(\\frac{\\texttt{card}(\\mathcal{C}) + 1}{\\texttt{card}\\bigl(\\{ d \\in \\mathcal{C} \\mid t \\in d \\}\\bigr) + 1}\\right). $$\n",
    "The addition of $1$ in both nominator and denominator is called <em style=\"color:blue;\">Laplace smoothing</em>.  This is necessary to prevent a **division by zero** error \n",
    "for those terms $t$ that do not occur in the list `Common_Words`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Compute the Feature Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function $\\texttt{feature_matrix}(\\texttt{spam_dir}, \\texttt{ham_dir})$ takes two directories that contain spam and ham, respectively.\n",
    "It computes a matrix $X$ and a vector $Y$, where $X$ is the feature matrix and for\n",
    "every row $r$ of the feature matrix, $Y[r]$ is 1 if the mail is ham and 0 if it's spam.\n",
    "\n",
    "The way $X$ is computed is quite inefficient, it would have been better to initialize $X$ as a matrix with the shape $(N,M)$, where $N$ is the number of mails and $M$ is the number of common words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_matrix(spam_dir, ham_dir):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for fn in os.listdir(spam_dir):\n",
    "        X.append(get_word_vector(spam_dir + fn))\n",
    "        Y.append(0)\n",
    "    for fn in os.listdir(ham_dir):    \n",
    "        X.append(get_word_vector(ham_dir + fn))\n",
    "        Y.append(+1)\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert the training set into a feature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 751 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train, Y_train = feature_matrix(spam_dir_train, ham__dir_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up to now, the feature matrix contains only the term frequencies.  Next we multiply with the inverse document frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, _ = X_train.shape\n",
    "IDF  = {}\n",
    "for w, i in Index_Dict.items():\n",
    "    IDF[w] = np.log((N + 1) / (Word_Counter[w] + 1))\n",
    "    X_train[:, i] = X_train[:, i] * IDF[w]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build the feature matrix for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, Y_test = feature_matrix(spam_dir_test, ham__dir_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w, i in Index_Dict.items():\n",
    "    X_test[:, i] = X_test[:, i] * IDF[w]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Train and Test a Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.svm as svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train an SVM and compute the accuracy on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = svm.SVC(kernel='linear', C=100000)\n",
    "M.fit  (X_train, Y_train)\n",
    "M.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the accuracy for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9884615384615385"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
